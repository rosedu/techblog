<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>ROSEdu Techblog</title>
        <link>http://techblog.rosedu.org</link>
        <description><![CDATA[ROSEdu Techblog]]></description>
        <atom:link href="http://techblog.rosedu.org/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Sun, 30 Mar 2014 00:00:00 UT</lastBuildDate>
        <item>
    <title>Here be Dragons - The Interesting Realm of Floating Point Operations</title>
    <link>http://techblog.rosedu.org/fp-dragons.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/fp-dragons.html" title="Here be Dragons - The Interesting Realm of Floating Point Operations">Here be Dragons - The Interesting Realm of Floating Point Operations</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on March 30, 2014</span>
      by
      <span class="author"><a href="/people/mihai-maruseac.html">Mihai Maruseac</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/floating-point.html">floating point</a>, <a href="/tags/numerical-methods.html">numerical methods</a>, <a href="/tags/approximate-algorithms.html">approximate algorithms</a>, <a href="/tags/fast-transcedental-functions.html">fast transcedental functions</a>, <a href="/tags/fast-inverse-square-root.html">fast inverse square root</a></span>
      </span>

      <p>In every programmer’s life there comes a time when he has to leave the realm of integers and tread into the dangerous land of rational numbers. He/she might do some scientific computation, or work on a financial application or a game rendering pipeline or even in some artificial intelligence or data-mining algorithm – in all of these cases and many others, restricting oneself to using only integers is no longer feasible.</p>
<p>And, as soon as one starts using floating point a lot of interesting things happen, starting from results which don’t show up nicely and bad equality testing and going towards subtler and subtler bugs.</p>
<p><img src="http://imgs.xkcd.com/comics/e_to_the_pi_minus_pi.png" alt="e to pi
minus pi" title="e to pi minus pi"></p>
<p>Even experts and common-sense is at fault in this realm. For example, did you know that <em>always</em> comparing two floating points like in the following code is <em>bad</em>?</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="kw">if</span> (fabs(a - b) &lt; <span class="fl">0.0001</span>)
    do_something_with_equal_numbers(a);</code></pre>
<p>Without being a complete guide, this article shows some of the beauties and dangers of the floating-point realm.</p>
<!--more-->

<section id="a-common-pitfall" class="level3">
<h3>A common pitfall</h3>
<p>Beginners programmers expect floating point number to act as the real fractional numbers: no errors involved. Slightly experienced programmers know that this is not the case, yet even the most careful and experienced ones make mistakes from time to time. We will focus more on the common pitfalls and not on the occasional mistreatments given by experts.</p>
<p>For example, someone unprepared might write the following code</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;stdio.h&gt;</span>
<span class="ot">#include &lt;stdlib.h&gt;</span>

<span class="dt">int</span> main ()
{
    <span class="dt">float</span> a = <span class="fl">0.1</span>;
    <span class="dt">float</span> b = <span class="fl">0.2</span>;
    <span class="dt">float</span> c = a + b;
    <span class="kw">if</span> (c != <span class="fl">0.3</span>)
        printf(<span class="st">&quot;%f</span><span class="ch">\n</span><span class="st">%f</span><span class="ch">\n</span><span class="st">%f</span><span class="ch">\n</span><span class="st">%f</span><span class="ch">\n</span><span class="st">&quot;</span>, c, a + b, <span class="dv">3</span> * a, <span class="fl">1.5</span> * b);
    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>and be surprised to see that results are</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">./a.out</span>
<span class="kw">0.300000</span>
<span class="kw">0.300000</span>
<span class="kw">0.300000</span>
<span class="kw">0.300000</span></code></pre>
<p><em>Note</em>: Your results on your machine might vary. <a href="#determinism-correctness-and-fastness">Later in the article</a> we will discuss this aspect at length.</p>
<p>Of course, the problem in here is pretty simple: all floating point constants use double precision thus the code should <em>at least</em> read</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="kw">if</span> (c != <span class="fl">0.</span>3f)
    printf(...)</code></pre>
<p>I say <em>at least</em> because even if on my architecture I got the exact value of <code>0.3</code>, this is not the case on all of them. Why? Because none of the <code>0.1</code>, <code>0.2</code> and <code>0.3</code> values have an exact representation in base 2. One can see that by trying to convert the number into base 2. Let’s follow the example of <code>0.3</code>:</p>
<ul>
<li>the integral part of <code>0.3</code> is <code>0</code> so it is also in base 2</li>
<li>double the number, we get <code>0.6</code>, its integral part is <code>0</code> thus the first binary digit after decimal point of <code>0.3</code> is still a <code>0</code>.</li>
<li>double this result, we get <code>1.2</code> so the next digit is a <code>1</code> and we are left with <code>0.2</code></li>
<li>double it, get <code>0.4</code>, next binary digit is <code>0</code></li>
<li>double it, get <code>0.8</code>, next binary digit is <code>0</code></li>
<li>double it, get <code>1.6</code>, next binary digit is <code>1</code> and we’re back to <code>0.6</code></li>
</ul>
<p>Thus, the binary representation of <code>0.3</code> would be <code>0.01001100110011001..</code>. Repeating the same algorithm with <code>0.1</code> and <code>0.2</code> will end in the same loop between <code>0.2</code>, <code>0.4</code>, <code>0.8</code> and <code>0.6</code>. So, none of <code>0.1</code>, <code>0.2</code> or <code>0.3</code> has an exact representation. Thus, no result of any operation with these numbers will be an exact answer.</p>
<p>But, then, why did we get the exact answer in here? The two sensible answers are that either the compiler generates code which uses a higher level of precision than the space reserved for float or the printing routine does hard work to properly display the numbers. We can test these hypotheses using <code>gdb</code>:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">$ gdb -q ./a.out 
Reading symbols from /tmp/fps/a.out...done.
(gdb) b main
Breakpoint <span class="dv">1</span> at <span class="bn">0x400538</span>: file <span class="fl">1.</span>c, line <span class="dv">6</span>.
(gdb) r
Starting program: /tmp/fps/a.out 

Breakpoint <span class="dv">1</span>, main () at <span class="fl">1.</span>c:<span class="dv">6</span>
<span class="dv">6</span>       <span class="dt">float</span> a = <span class="fl">0.1</span>;
(gdb) n
<span class="dv">7</span>       <span class="dt">float</span> b = <span class="fl">0.2</span>;
(gdb) p a
$<span class="dv">1</span> = <span class="fl">0.100000001</span>
(gdb) n
<span class="dv">8</span>       <span class="dt">float</span> c = a + b;
(gdb) p b
$<span class="dv">2</span> = <span class="fl">0.200000003</span></code></pre>
<p>As you can see, printing the values from memory shows that they are not <code>0.1</code> and <code>0.2</code> but values close to that.</p>
<p>Let’s see now what the assembly code around <code>c = a + b</code> looks like:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">(gdb) disass
Dump of assembler code <span class="kw">for</span> function main:
   <span class="bn">0x0000000000400530</span> &lt;+<span class="dv">0</span>&gt;:     push   %rbp
   <span class="bn">0x0000000000400531</span> &lt;+<span class="dv">1</span>&gt;:     mov    %rsp,%rbp
   <span class="bn">0x0000000000400534</span> &lt;+<span class="dv">4</span>&gt;:     sub    $<span class="bn">0x10</span>,%rsp
   <span class="bn">0x0000000000400538</span> &lt;+<span class="dv">8</span>&gt;:     mov    <span class="bn">0x142</span>(%rip),%eax        # <span class="bn">0x400680</span>
   <span class="bn">0x000000000040053e</span> &lt;+<span class="dv">14</span>&gt;:    mov    %eax,-<span class="bn">0x4</span>(%rbp)
   <span class="bn">0x0000000000400541</span> &lt;+<span class="dv">17</span>&gt;:    mov    <span class="bn">0x13d</span>(%rip),%eax        # <span class="bn">0x400684</span>
   <span class="bn">0x0000000000400547</span> &lt;+<span class="dv">23</span>&gt;:    mov    %eax,-<span class="bn">0x8</span>(%rbp)
=&gt; <span class="bn">0x000000000040054a</span> &lt;+<span class="dv">26</span>&gt;:    movss  -<span class="bn">0x4</span>(%rbp),%xmm0
   <span class="bn">0x000000000040054f</span> &lt;+<span class="dv">31</span>&gt;:    addss  -<span class="bn">0x8</span>(%rbp),%xmm0
   <span class="bn">0x0000000000400554</span> &lt;+<span class="dv">36</span>&gt;:    movss  %xmm0,-<span class="bn">0xc</span>(%rbp)
---Type &lt;<span class="kw">return</span>&gt; to <span class="kw">continue</span>, <span class="kw">or</span> q &lt;<span class="kw">return</span>&gt; to quit---q
Quit</code></pre>
<p>The last three lines are the assembly lines generated for <code>float c = a + b</code> (you can test that by running an <code>objdump -CDgS | less</code> and searching for <code>float c</code>). <code>-0x4(%rbp)</code> is where <code>a</code> is stored on the stack. <code>b</code> is stored at <code>-0x8(%rbp)</code>. The assembly instructions used – <code>addss</code> and <code>movss</code> – and the register involved – <code>xmm0</code> – show that we are working with <a href="http://en.wikipedia.org/wiki/Streaming_SIMD_Extensions" title="SSE - Wikipedia">Streaming SIMD Extensions (SSE)</a>. This register has a precision of 128 bits which is 4 times greater than the 32 bits used by the <code>float</code> datatype. We are tempted now to think that we are able to use the full width of the register – even if the SIMD part of the extension tells that this is not the case, we want a real proof based on the memory/register contents.</p>
<p>Continuing the execution, we see:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">(gdb) n
<span class="dv">9</span>       <span class="kw">if</span> (c != <span class="fl">0.3</span>)
(gdb) p $xmm0
$<span class="dv">3</span> = {v4_float = {<span class="fl">0.300000012</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>}, v2_double = {<span class="fl">5.18894283457103e-315</span>,
<span class="dv">0</span>}, v16_int8 = {-<span class="dv">102</span>, -<span class="dv">103</span>, -<span class="dv">103</span>, <span class="dv">62</span>, <span class="dv">0</span> &lt;repeats <span class="dv">12</span> times&gt;}, v8_int16 = {
-<span class="dv">26214</span>, <span class="dv">16025</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>}, v4_int32 = {<span class="dv">1050253722</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>}, v2_int64 =
{<span class="dv">1050253722</span>, <span class="dv">0</span>}, uint128 = <span class="dv">1050253722</span>}
(gdb) p c
$<span class="dv">4</span> = <span class="fl">0.300000012</span></code></pre>
<p>Indeed, our <code>c</code> is not <code>0.3</code>. But it seems that not even the contents of <code>xmm0</code> are closer to the truth.</p>
<p>So, the fact that we got <code>0.3</code> in the output is caused not by the fact that we use a 128-bits wide registers but by the fact that the <a href="http://kurtstephens.com/files/p372-steele.pdf" title="Printing Floating Point Numbers (PDF)">up-to-recent unsolved problem</a> of precisely printing floating point numbers is no longer so.</p>
</section>
<section id="the-floating-point-standard" class="level3">
<h3>The floating point standard</h3>
<p>Before we further investigate the realm of floating points, let’s have a look at the standard used for storing and working with these numbers: <a href="http://en.wikipedia.org/wiki/IEEE_754" title="IEEE-754 - Wikipedia">IEEE-754</a>. We would not go in full details since we are only interested in some minor aspects.</p>
<p>First of all, the standard defines the way in which we can store a floating point number as three integer numbers: one for the sign (which is always <code>0</code> or <code>1</code>), one for an exponent which gives us access to a wider range than<code>[0..2^32]</code> and one for the mantissa. The final number is just the product of the mantissa, the base (2 in case of binary numbers, 10 in case of decimal numbers – the standard defines some way to store decimal numbers too) raised to the exponent power and <code>(-1)</code> raised to the sign value.</p>
<p>Depending on the sizes of these numbers we have the basic <code>float</code> type (or <code>binary32</code>) in which the total size of the three numbers is 32 bits. In this case 1 bit is reserved for the sign, 8 for the exponent and the other 23 for the mantissa.</p>
<p>The C <code>double</code> type is defined by the <code>binary64</code> format: 1 bit of sign, 11 bits for the exponent and 52 bits for the mantissa for a total of 64. There is also a <code>binary128</code> format and a C <code>long double</code> type. In this case 15 bits are reserved for the exponent and 112 for the mantissa.</p>
<p>The standard committee has come up with a clever idea of storing these numbers into binary format. For example, they don’t store the exponent in 2’s complement but modified via an offset. Thus, <strong>the bit patterns of two nearby representable floats represent two consecutive integer values</strong>. This allows us to do some interesting <a href="#fun-trivia">tricks</a> with the two representations of real numbers.</p>
<p>The standard also defines <span class="math">\(\infty\)</span> and <span class="math">\(-\infty\)</span>, two values for <code>0</code> (<code>+0</code> and <code>-0</code> and how they should be tested equal but treated differently in operations) and a full sequence of values which don’t represent a number but some exception – the sometimes dreaded <code>NaN</code> values.</p>
<p>Knowing these details about the IEEE-754 standard we can go forward in our exploration. Because from now on we would use the binary representation and won’t rely on the base <code>10</code> view of numbers we will use <a href="http://babbage.cs.qc.cuny.edu/IEEE-754/" title="IEEE-754 Analysis">an online analyzer</a> to investigate interesting values.</p>
</section>
<section id="back-to-the-castle-and-a-final-conclusion" class="level3">
<h3>Back to the castle and a final conclusion</h3>
<p>Returning to our code, we want to see what values are stored in memory for <code>a</code>, <code>b</code> and <code>c</code> and also in register <code>xmm0</code>:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">(gdb) x $rbp - <span class="bn">0x4</span>
<span class="bn">0x7fffffffdfac</span>: <span class="bn">0x3dcccccd</span>
(gdb) x $rbp - <span class="bn">0x8</span>
<span class="bn">0x7fffffffdfa8</span>: <span class="bn">0x3e4ccccd</span>
(gdb) x $rbp - <span class="bn">0xc</span>
<span class="bn">0x7fffffffdfa4</span>: <span class="bn">0x3e99999a</span>
(gdb) p/x $xmm0
$<span class="dv">4</span> = {.... uint128 = <span class="bn">0x0000000000000000000000003e99999a</span>}</code></pre>
<p>Looking through the analyzer, <code>0x3dcccccd</code> (the value for <code>a</code>) is <code>1.00000001490116119384765625E-1</code> which is both close to the original value of <code>0.1</code> and to the displayed value of <code>0.100000001</code>. Same for <code>b</code> and <code>c</code>. However, looking at <code>xmm0</code> register we see that the last 32 bits have the same pattern as <code>-0xc($rbp)</code>. Thus, the SSE 128 bits registers <strong>are not using</strong> the <code>binary128</code> standard! If they were using it, the last value displayed there should have been <code>3FFD3333333333333333333333333333</code>.</p>
<p>Now it is time to see some other aspects of working with floating point numbers.</p>
</section>
<section id="testing-them-all" class="level3">
<h3>Testing them all</h3>
<p>Since there is a perfect isomorphism between <code>float</code> values and <code>int</code> ones and there are only <code>2^32</code> ints (on normal architectures), sometimes it is easy and desirable to test a new function on all of the possible values. Unfortunately, this doesn’t properly work for functions with more than one argument because one would have to spend ages for that. But for one single argument things are pretty nice: it only takes 16 seconds on my machine to run the following code which tests that changing the sign twice gives the same value:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;stdio.h&gt;</span>
<span class="ot">#include &lt;stdlib.h&gt;</span>

<span class="dt">int</span> main()
{
    <span class="dt">unsigned</span> <span class="dt">int</span> i = <span class="dv">0</span>;
    <span class="dt">float</span> x;

    <span class="kw">do</span> {
        x = *((<span class="dt">float</span>*)&amp;i);
        <span class="kw">if</span> (x != -(-x))
            printf(<span class="st">&quot;%f %u</span><span class="ch">\n</span><span class="st">&quot;</span>, x, i);
        i++;
    } <span class="kw">while</span> (i != <span class="dv">0</span>);

    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>Running it we see:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">gcc</span> -Wall -Wextra -O0 -g 2.c 
$ <span class="kw">./a.out</span>  <span class="kw">|</span> <span class="kw">head</span> -n 5
<span class="kw">nan</span> 2139095041
<span class="kw">nan</span> 2139095042
<span class="kw">nan</span> 2139095043
<span class="kw">nan</span> 2139095044
<span class="kw">nan</span> 2139095045</code></pre>
<p>It seems that our hypothesis fails when the initial number was a <code>NaN</code> value. For now, let us filter all of these values and test the hypothesis on the remaining domain.</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">time</span> ./a.out <span class="kw">|</span> <span class="kw">grep</span> -v nan

<span class="kw">real</span>    0m15.895s
<span class="kw">user</span>    0m17.977s
<span class="kw">sys</span> 0m0.163s</code></pre>
<p>Something which we would have expected.</p>
<p><em>Note</em>: Compiling with optimisations on might make the compiler issue the following warning:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">warning: dereferencing type-punned pointer will <span class="kw">break</span> strict-aliasing rules [-Wstrict-aliasing]
    ^</code></pre>
<p>This is because the C/C++ standard says that the compiler can assume that different types don’t overlap in memory so neither should pointers to those types. Knowing that a pointer to an array of integers and one array of doubles don’t overlap opens a way for some optimizations. Breaking them is at your own risk. See also the documentation for <code>-fstrict-aliasing</code> flag of <code>gcc</code>.</p>
</section>
<section id="the-nan-problem" class="level3">
<h3>The NaN problem</h3>
<p>You might be wondering why do we have so many <code>NaN</code> values (the 5 above are but a small sample of them all). Thing is, the standard allows some <code>NaN</code> values to carry an exception code within it such that the programmer debugging the code can know why he got this value. We would not enter into details regarding this aspect though.</p>
<p>A more interesting question is how these <code>NaN</code> values arise. One example is doing <code>asin(1+smth)</code> or <code>sqrt(0-smth_else)</code>. You might say: “but I will never do that” to which I will reply that since every floating point operation has some rounding and errors tend to propagate you might find in some occasions doing exactly that.</p>
<p>Now, the question is how to filter out these values from code. The standard states that the <code>NaN</code> values have form <code>s1111111 1axxxxxx xxxxxxxx xxxxxxxx</code> so one might just check the first few bits of the number (<code>s</code> is the sign and is ignored and <code>a</code> is used to differentiate between a quiet <code>NaN</code> and a signalling one while <code>x</code> represent payload bits showing why the signalling <code>NaN</code> was produced). So we change the code to read</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;stdio.h&gt;</span>
<span class="ot">#include &lt;stdlib.h&gt;</span>

<span class="dt">int</span> main()
{
    <span class="dt">unsigned</span> <span class="dt">int</span> i = <span class="dv">0</span>;
    <span class="dt">float</span> x;

    <span class="kw">do</span> {
        x = *((<span class="dt">float</span>*)&amp;i);
        <span class="kw">if</span> (x != -(-x))
            printf(<span class="st">&quot;%f %u</span><span class="ch">\n</span><span class="st">&quot;</span>, x, i);
        i++;
        <span class="kw">if</span> (i &gt; <span class="bn">0x7f800000</span>)
            <span class="kw">break</span>;
    } <span class="kw">while</span> (i != <span class="dv">0</span>);

    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>If you don’t remember the bit pattern you can still filter out by knowing that all <code>NaN</code> values are required to compare unequal even themselves. Thus, a test <code>x == x</code> is always false for <code>NaN</code> values.</p>
</section>
<section id="the-associativity-problem" class="level3">
<h3>The Associativity Problem</h3>
<p>One of the ideas behind this post was <a href="http://stackoverflow.com/questions/6430448/why-doesnt-gcc-optimize-aaaaaa-to-aaaaaa" title="Why doesn&#39;t GCC optimize...">this StackOverflow question</a>. We can test this to see on how many floats the output is wrong:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;stdio.h&gt;</span>
<span class="ot">#include &lt;stdlib.h&gt;</span>

<span class="dt">int</span> main()
{
    <span class="dt">unsigned</span> <span class="dt">int</span> i = <span class="dv">0</span>;
    <span class="dt">float</span> x, y, z;
    <span class="dt">unsigned</span> <span class="dt">long</span> <span class="dt">long</span> s = <span class="dv">0</span>;

    <span class="kw">do</span> {
        x = *((<span class="dt">float</span>*)&amp;i);
        y = x * x * x * x * x * x;
        z = (x * x * x);
        z = z * z;
        <span class="kw">if</span> (y != z)
            printf(<span class="st">&quot;%f %u</span><span class="ch">\n</span><span class="st">&quot;</span>, x, i);
        s += i;
        i++;
        <span class="kw">if</span> (i &gt; <span class="bn">0x7f800000</span>)
            <span class="kw">break</span>;
    } <span class="kw">while</span> (i != <span class="dv">0</span>);

    printf(<span class="st">&quot;%lld</span><span class="ch">\n</span><span class="st">&quot;</span>, s);

    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>Since we are compiling with <code>-O3</code> we don’t want the compiler to optimize our loop away. Thus we have a <code>s</code> variable in which we store the sum of all <code>i</code>s. Also, the code already removes the <code>NaN</code> values. Running it we get:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">time</span> ./a.out <span class="kw">|</span> <span class="kw">wc</span> -l
<span class="kw">163049703</span>

<span class="kw">real</span>    1m58.114s
<span class="kw">user</span>    1m59.005s
<span class="kw">sys</span> 0m3.148s</code></pre>
<p>That is, there is a total of 3.79% values for which doing the optimization in question will give a different result on this machine.</p>
</section>
<section id="equality-testing-done-right" class="level3">
<h3>Equality testing done right</h3>
<p>Finally, we have arrived to an interesting aspect: how do we compare if two floats are almost the same? We already know that doing a comparison with <code>==</code> is bad. Let us pick now two numbers: <code>10000</code> and the next representable float and compare between them using the standard method:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;math.h&gt;</span>
<span class="ot">#include &lt;stdio.h&gt;</span>
<span class="ot">#include &lt;stdlib.h&gt;</span>

<span class="dt">int</span> main ()
{
    <span class="dt">int</span> expectedAsInt = <span class="dv">1176256512</span>;
    <span class="dt">int</span> resultAsInt = expectedAsInt + <span class="dv">1</span>;
    <span class="dt">float</span> expectedResult = *((<span class="dt">float</span>*)&amp;expectedAsInt);
    <span class="dt">float</span> result = *((<span class="dt">float</span>*)&amp;resultAsInt);

    printf(<span class="st">&quot;%f %f</span><span class="ch">\n</span><span class="st">&quot;</span>, result, expectedResult);

    <span class="kw">if</span> (fabs(result - expectedResult) &lt; <span class="fl">0.0001</span>)
        printf(<span class="st">&quot;Numbers are close</span><span class="ch">\n</span><span class="st">&quot;</span>);

    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>The output</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">./a.out</span>
<span class="kw">10000.000977</span> 10000.000000</code></pre>
<p>So the above test fails to consider two floating points which are neighbors as being the same. If your algorithm produced a <code>result</code> which would be between these two floats and it would be rounded to the wrong one you would get the impression that your algorithm is wrong.</p>
<p>Anyway, even if this method was correct, what value should one use for the bound in the test? <code>float.h</code> defines <code>FLT_EPSILON</code> so one might decide to test using that:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;float.h&gt;</span>
<span class="ot">#include &lt;math.h&gt;</span>
<span class="ot">#include &lt;stdio.h&gt;</span>
<span class="ot">#include &lt;stdlib.h&gt;</span>

<span class="dt">int</span> closeFloats(<span class="dt">float</span> number, <span class="dt">float</span> target)
{
    <span class="kw">return</span> fabs(number - target) &lt; FLT_EPSILON;
}

<span class="kw">inline</span> <span class="dt">float</span> getFloatFromInt(<span class="dt">int</span> value)
{
    <span class="kw">return</span> *((<span class="dt">float</span>*)&amp;value);
}

<span class="dt">void</span> testFloatTesting(<span class="dt">int</span> src)
{
    <span class="dt">float</span> target = getFloatFromInt(src);
    <span class="dt">float</span> next = getFloatFromInt(src + <span class="dv">1</span>);

    printf(<span class="st">&quot;src=%d target=%f next=%f compare=%d</span><span class="ch">\n</span><span class="st">&quot;</span>, src, target, next,
            closeFloats(next, target));
}

<span class="dt">int</span> main ()
{
    <span class="co">/* 0.5 and next float */</span>
    testFloatTesting(<span class="bn">0x3F000000</span>);

    <span class="co">/* 1.5 and next float */</span>
    testFloatTesting(<span class="bn">0x3FC00000</span>);

    <span class="co">/* 100.5 and next float */</span>
    testFloatTesting(<span class="bn">0x42C90000</span>);

    <span class="co">/* 10000.5 and next float */</span>
    testFloatTesting(<span class="bn">0x461C4200</span>);

    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>A proper <code>closeFloats</code> function is what we are looking for. We use <code>testFloatTesting</code> to test this on two floats which come from two neighboring integers (a more formal definition is floats which differ by 1ULP – <em>units in last place</em>). Running it, we get:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">./a.out</span>
<span class="ot">src=</span>1056964608 <span class="ot">target=</span>0.500000 <span class="ot">next=</span>0.500000 <span class="ot">compare=</span>1
<span class="ot">src=</span>1069547520 <span class="ot">target=</span>1.500000 <span class="ot">next=</span>1.500000 <span class="ot">compare=</span>0
<span class="ot">src=</span>1120468992 <span class="ot">target=</span>100.500000 <span class="ot">next=</span>100.500008 <span class="ot">compare=</span>0
<span class="ot">src=</span>1176257024 <span class="ot">target=</span>10000.500000 <span class="ot">next=</span>10000.500977 <span class="ot">compare=</span>0</code></pre>
<p>All of the initial numbers were chosen to be exactly representable but this is not vital. What’s interesting is that only the numbers between 0 and 1 show as being close when using the <code>FLT_EPSILON</code> absolute method.</p>
<p>Let’s try now to use a relative error and compare that with <code>FLT_EPSILON</code>:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="dt">int</span> closeFloats(<span class="dt">float</span> number, <span class="dt">float</span> target)
{
    <span class="kw">return</span> fabs(number - target) / target &lt; FLT_EPSILON;
}</code></pre>
<p>Using the above gives the following results:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">$ ./a.out 
src=<span class="dv">1056964608</span> target=<span class="fl">0.500000</span> next=<span class="fl">0.500000</span> compare=<span class="dv">0</span>
src=<span class="dv">1069547520</span> target=<span class="fl">1.500000</span> next=<span class="fl">1.500000</span> compare=<span class="dv">1</span>
src=<span class="dv">1120468992</span> target=<span class="fl">100.500000</span> next=<span class="fl">100.500008</span> compare=<span class="dv">1</span>
src=<span class="dv">1176257024</span> target=<span class="fl">10000.500000</span> next=<span class="fl">10000.500977</span> compare=<span class="dv">1</span></code></pre>
<p>We get better results above 1 but worse below. This is because we are dividing to a smaller number closing to doing a division by <code>0</code>. So, don’t use the above method as well.</p>
<p>Let’s try with a third option:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="dt">int</span> closeFloats(<span class="dt">float</span> number, <span class="dt">float</span> target)
{
    <span class="dt">float</span> diff = fabs(number - target);
    <span class="dt">float</span> largest;

    number = fabs(number);
    target = fabs(target);
    largest = (target &gt; number) ? target : number;

    <span class="kw">return</span> diff &lt;= largest * FLT_EPSILON;
}</code></pre>
<p>This time, instead of dividing we use multiplication. Also, to ensure some more safety, we pick the largest absolute value as being the mark around which we compute the relative error. Running this test we finally get:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">$ ./a.out
src=<span class="dv">1056964608</span> target=<span class="fl">0.500000</span> next=<span class="fl">0.500000</span> compare=<span class="dv">1</span>
src=<span class="dv">1069547520</span> target=<span class="fl">1.500000</span> next=<span class="fl">1.500000</span> compare=<span class="dv">1</span>
src=<span class="dv">1120468992</span> target=<span class="fl">100.500000</span> next=<span class="fl">100.500008</span> compare=<span class="dv">1</span>
src=<span class="dv">1176257024</span> target=<span class="fl">10000.500000</span> next=<span class="fl">10000.500977</span> compare=<span class="dv">1</span></code></pre>
<p>However, the story is not yet finished. What happens if the <code>FLT_EPSILON</code> is too large a gap in relative error? You might be tempted to say <em>just multiply <code>FLT_EPSILON</code> with <code>0.1</code> and be done</em>. Test it and you’ll see that all of the results turn to <code>0</code>: it is as if <strong>we didn’t use any bound at all and tested using <code>==</code></strong>. So we are thus restricted to having a relative gap no smaller than <code>FLT_EPSILON</code>.</p>
<p>Now, let’s turn to the other side: what if the gap is too small? You can multiply <code>FLT_EPSILON</code> with a small value for this. However, finding out which value to use is hard because this way of computing the error is not linked at all with the representation of the floating point numbers. So, let’s try with using ULPs:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="dt">int</span> closeFloats(<span class="dt">float</span> number, <span class="dt">float</span> target)
{
	<span class="dt">int</span> numberULP = *((<span class="dt">int</span> *) &amp;number);
	<span class="dt">int</span> targetULP = *((<span class="dt">int</span> *) &amp;target);

	<span class="kw">if</span> ((numberULP &gt;&gt; <span class="dv">31</span>) != (targetULP &gt;&gt; <span class="dv">31</span>))
		<span class="kw">return</span> number == target;
	<span class="kw">return</span> abs(numberULP - targetULP) &lt; <span class="dv">5</span>;
}</code></pre>
<p>In the above we consider numbers which differ by at most 5 ULPs as being close. Also, observe the first check which tests if the numbers have different signs. In the positive case we compare using <code>==</code> the <strong>floating point numbers</strong> to ensure that we catch the case <code>+0 == -0</code>.</p>
<p>Running it we get:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">$ ./a.out
src=<span class="dv">1056964608</span> target=<span class="fl">0.500000</span> next=<span class="fl">0.500000</span> compare=<span class="dv">1</span>
src=<span class="dv">1069547520</span> target=<span class="fl">1.500000</span> next=<span class="fl">1.500000</span> compare=<span class="dv">1</span>
src=<span class="dv">1120468992</span> target=<span class="fl">100.500000</span> next=<span class="fl">100.500008</span> compare=<span class="dv">1</span>
src=<span class="dv">1176257024</span> target=<span class="fl">10000.500000</span> next=<span class="fl">10000.500977</span> compare=<span class="dv">1</span></code></pre>
<p>which was somehow obvious (since the number are already one ULP apart).</p>
<p>Now you might raise one more question: which of the two methods is fastest? Let’s test:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="dt">void</span> testFloatTesting(<span class="dt">int</span> src)
{
    <span class="dt">float</span> target = getFloatFromInt(src);
    <span class="dt">float</span> next = getFloatFromInt(src + <span class="dv">1</span>);

    <span class="kw">if</span> (closeFloats(next, target) != <span class="dv">1</span>)
        printf(<span class="st">&quot;src=%d target=%f next=%f compare=%d</span><span class="ch">\n</span><span class="st">&quot;</span>, src, target,
                next, closeFloats(next, target));
}

<span class="dt">int</span> main ()
{
    <span class="dt">unsigned</span> <span class="dt">int</span> i = <span class="dv">0</span>;

    <span class="kw">do</span> {
        testFloatTesting(i++);
        <span class="kw">if</span> (i &gt; <span class="bn">0x7f800000</span>)
            <span class="kw">break</span>;
    } <span class="kw">while</span> (i != <span class="dv">0</span>);

    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>Using ULP we get these results:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">$ time ./a.out

real    0m32.343s
user    0m32.290s
sys 0m0.007s</code></pre>
<p>Using the floating point - relative method we get:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">$ time ./a.out | wc -l
<span class="dv">4194305</span>

real    1m4.161s
user    1m4.137s
sys 0m0.204s</code></pre>
<p>We seem to be getting some wrong results (<code>0.9%</code>). Indeed, around 0 both comparison methods fail. The relative error method fails because we are close to dividing by <code>0</code> and because of catastrophic cancellation. The ULP method because there are many numbers between 0 and <code>FLT_MIN</code> (the minimum properly representable float) – these values are denormalized and using them might slow down your computation quite a lot. So, what should we use in this case? It turns out that if you want to compare with <code>0</code> the absolute error method is the best.</p>
<p>Also note that on my machine the relative method is twice as slow as the ULP one.</p>
<p>To conclude this part:</p>
<ul>
<li>when you compare two numbers which are far from 0 (properly representable) use either the relative error method (with multiplication) or the ULP one, depending on which is fastest (on machines with SSE this would most certainly by the ULP one).</li>
<li>when comparing a number against 0 use the absolute error method</li>
<li>in all other cases take care to split the comparison into the above two cases</li>
</ul>
</section>
<section id="determinism-correctness-and-fastness" class="level3">
<h3>Determinism, Correctness and Fastness</h3>
<p>Up to this point, this article focused on the correctness aspect of floating point operations where by correctness one means giving results as close as possible to the real truth. Not mentioned in here but on the same topic we have the field of <a href="http://en.wikipedia.org/wiki/Numerical_stability" title="Numerical stability - Wikipedia">numerically stable algorithms</a> and the entire mathematics/CS branch of <a href="http://en.wikipedia.org/wiki/Numerical_analysis" title="Numerical Analysis - Wikipedia">numerical analysis</a>.</p>
<p>However, there is another aspect which needs to be considered. We have written even in this article <em>the results you get might differ</em> depending on the architecture you use. And indeed, neither IEEE nor C/C++ standards define what precision should be use for intermediate computations. Even though the IEEE-754-2008 standard says <em>Together with language controls it should be possible to write programs that produce identical results on all conforming systems</em>, this is just a possibility, not yet mandated across architectures.</p>
<p>When is this important? Three domains come to mind: games (network games and game replays), research (reproducibility), cloud computing (migration of live virtual machines). All of them are important enough to make this problem an interesting one.</p>
<p>There are settings which change the rounding mode, the handling of denormals or of exceptions. There are a lot of flags to control and you can find them all described in <code>fenv.h</code> header. These values are per-thread but they might change if you call a library function which has the side effect of modifying one of these flags and not changing it back to the previous value (another strong point of referential immutability).</p>
<p>Finally, floating point results might also change depending on the compilation flags passed (<code>-ffast-math</code>) or even if you are running your code inside a debugger or in production mode. We’ll leave this topic by giving <a href="http://randomascii.wordpress.com/2013/07/16/floating-point-determinism/" title="Random Ascii - Floating Point Determinism">a link to a comprehensive article</a> about it. If one really needs reproducible floating point results then he might use <a href="http://nicolas.brodu.net/en/programmation/streflop/" title="STand-alone REproducible FLoating point OPerations">Streflop</a> or even <a href="http://www.mpfr.org/mpfr-current/" title="GNU MPFR">MPFR</a>.</p>
<p>Now, let’s turn to the third topic: <em>fastness</em>. It turns out that all floating point operations are slow. To alleviate this problem several CPU extensions were introduced – that’s why we have SSE. But it turns out that we can do even better than that if we leave some room for some errors.</p>
<p>Games and Artificial Intelligence use quite a lot of floating point operations with transcendental functions (<code>sin</code>, <code>log</code>, <code>exp</code>). These have been the subject of optimizations through time. We have <a href="http://en.wikipedia.org/wiki/Fast_inverse_square_root" title="Fast inverse square root - Wikipedia">the fast-inverse-square-root trick</a> as a powerful example of that. We have <a href="http://nic.schraudolph.org/pubs/Schraudolph99.pdf" title="Fast approximation of exponential function (PDF)">fast approximations of exponential</a> function which is commonly used in neural networks and radial basis functions. And we have even libraries ([<a href="https://github.com/ekmett/approximate/blob/master/cbits/fast.c" title="approximate/cbits/fast.c - GitHub">1</a>], [<a href="https://code.google.com/p/fastapprox/" title="fastapprox - GoogleCode">2</a>]) dedicated to optimizing the speed of these functions in detriment of precision. At first look, all of these look like clever algorithms with a lot of magical constants which arise from (seemingly) nowhere. However, most of them are just simply usages of numerical methods to compute roots of equations (<a href="http://en.wikipedia.org/wiki/Newton&#39;s_method" title="Newton-Raphson method - Wikipedia">Newton-Raphson method</a> is used for the <a href="http://en.wikipedia.org/wiki/Fast_inverse_square_root" title="Fast inverse square root - Wikipedia">Carmak’s trick</a>) or some <a href="http://en.wikipedia.org/wiki/Taylor_series" title="Taylor series - Wikipedia">series expansions</a> of the functions being used coupled with clever usages of the integer representation of the floating point. Describing these algorithms will cover an article twice as long as this one so we won’t do it now. However, keep in mind that <a href="http://c2.com/cgi/wiki?PrematureOptimization" title="Premature Optimization">Knuth saying</a>:</p>
<blockquote>
<p>Premature optimization is the root of all evil</p>
</blockquote>
<p>Don’t just go and replace all of your transcendental calls from <code>libm</code> to calls from one of the libraries bent on optimizing the speed of some floating point operations, check first if this is exactly what you want and if the errors stemming from the approximations have no impact on your code/results.</p>
<p>To end this section, it seems that in the realm of floating point precision, reproducibility and speed are the vertices of an <a href="http://en.wikipedia.org/wiki/Project_management_triangle" title="Triple Constraint - Wikipedia">Iron Triangle</a>: one cannot get all of them at once and must make compromises.</p>
</section>
<section id="fun-trivia" class="level3">
<h3>Fun trivia</h3>
<p>To conclude the article on a funny note note that one can compute the logarithm in base two of any float by just looking at it’s representation from the integer point of view: since multiplying a float by 2 increases the exponent – which is stored in the middle of the representation – increasing the value of the logarithm by 1 is just increasing the representation by <code>0x800000</code>.</p>
<p>Another interesting fact is that since <span class="math">\(\sin(\pi-x) = \sin(x)\)</span> and for small values of <code>x</code> <span class="math">\(\sin(x) \approx x\)</span> we get that <span class="math">\(\sin(\pi) \approx \epsilon(\pi)\)</span> (the error in representing <span class="math">\(\pi\)</span> as a float). Thus, a nice method to compute <span class="math">\(\pi\)</span> is to repeatedly compute <code>pi + sin(pi)</code> up to the highest precision available. Don’t try this in production code, the <a href="http://www.xkcd.com/217/" title="e to pi minus pi">xkcd</a> reference in the beginning of the article should be warning enough: <code>sin(pi)</code> is not a rational function thus this method can quickly lead to catastrophic errors.</p>
</section>
<section id="conclusions" class="level3">
<h3>Conclusions</h3>
<p>This article is quite a long one and filled with seemingly disjoint pieces of information. They are but mere glimpses into the dangers of using floating point arithmetic without considering all of the aspects involved with it. For a more comprehensive reading the obligatory <a href="http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html" title="What Every Computer Scientist Should Know About Floating-Point Arithmetic">Oracle Appendix D</a> is essential but it is filled with mathematical formulas and equations which are daunting to the less brave readers. Some more details can be found in <a href="http://floating-point-gui.de/" title="The Floating Point Guide">The Floating Point Guide</a>.</p>
<p>In the end, keep in mind that floating point math is not mystical but neither should it be treated carelessly.</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Sun, 30 Mar 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/fp-dragons.html</guid>
</item>
<item>
    <title>Daemonizing Processes - Part 1</title>
    <link>http://techblog.rosedu.org/daemonizing-processes.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/daemonizing-processes.html" title="Daemonizing Processes - Part 1">Daemonizing Processes - Part 1</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on March 23, 2014</span>
      by
      <span class="author"><a href="/people/matei-oprea.html">Matei Oprea</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/c.html">C</a>, <a href="/tags/daemon.html">daemon</a>, <a href="/tags/fork.html">fork</a>, <a href="/tags/setsid.html">setsid</a>, <a href="/tags/nohup.html">nohup</a>, <a href="/tags/disown.html">disown</a></span>
      </span>

      <p>A special category of processes in Linux is that formed by <strong>daemon</strong> processes.</p>
<!--more-->

<section id="what-is-a-daemon" class="level3">
<h3>What is a daemon?</h3>
<p>A daemon is a program that runs as a background process, forever, without being directly affected by any user. Let’s run a command to see examples of some daemons.</p>
<p>We need to run a command which will tell us what processes are started by the <code>init</code> process (they must have a <code>PPID</code> of 1):</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">ps</span> -ef <span class="kw">|</span> <span class="kw">awk</span> <span class="st">&#39;$3 == 1&#39;</span></code></pre>
<p>The trimmed result will be the following:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">ps</span> -ef <span class="kw">|</span> <span class="kw">awk</span> <span class="st">&#39;$3 == 1&#39;</span>
<span class="kw">root</span>       367     1  0 Mar08 ?        00:00:00 upstart-udev-bridge --daemon
<span class="kw">root</span>       398     1  0 Mar08 ?        00:00:00 /sbin/udevd --daemon
<span class="kw">syslog</span>     521     1  0 Mar08 ?        00:00:03 rsyslogd -c5
<span class="kw">102</span>        525     1  0 Mar08 ?        00:00:15 dbus-daemon --system --fork --activation=upstart
<span class="kw">avahi</span>      816     1  0 Mar08 ?        00:00:00 avahi-daemon: running [matei-Satellite-C660.local]</code></pre>
<p>In Linux, the parent process of a daemon is often the <code>init</code> process. To create a daemon, we need to <code>fork()</code> a child process and then exit (after that the process will be an <em>orphan process</em>), causing <code>init</code> to adopt the it as a child. A daemon is often started at boot time having the task of handling network requests or hardware activity.</p>
</section>
<section id="lets-code-a-daemon" class="level3">
<h3>Let’s code a Daemon</h3>
<p>In this article we will show how one can write a simple daemon process. First, we will show the long path of using <code>fork()</code> and <code>setsid()</code>.</p>
<p>First step (see <a href="http://web.archive.org/web/20120914180018/http://www.steve.org.uk/Reference/Unix/faq_2.html#SEC16" title="How to code a daemon">this FAQ</a> for reference) is to <code>fork</code> and <code>exit</code> such that the process is no longer a process leader:</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="co">/*</span>
<span class="co"> * Fork the parent process</span>
<span class="co"> */</span>
pid = fork();
<span class="co">/* On failure, -1 is returned in the parent</span>
<span class="co"> * No child process is created</span>
<span class="co"> */</span>
<span class="kw">if</span> (pid &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;fork&quot;</span>);
    exit(EXIT_FAILURE);
}

<span class="co">/* We are now killing the parent process</span>
<span class="co"> * parent exits -&gt; init &quot;takes the lead&quot;</span>
<span class="co"> */</span>
<span class="kw">if</span> (pid &gt; <span class="dv">0</span>)
    exit(EXIT_SUCCESS);</code></pre>
<p>Because we want to have a completely new controlling terminal we need to make our process be a session leader using <code>setsid()</code>. The above <code>fork</code> was needed just to allow this to succeed:</p>
<pre class="sourceCode c"><code class="sourceCode c">sessionID=setsid();
<span class="kw">if</span> (sessionID &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;setsid&quot;</span>);
    exit(EXIT_FAILURE);
}</code></pre>
<p>Next step is to <code>fork()/exit()</code> again. Since the session leader is now dead our process can never get access to a controlling terminal:</p>
<pre class="sourceCode c"><code class="sourceCode c">pid = fork();
<span class="kw">if</span> (pid &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;fork&quot;</span>);
    exit(EXIT_FAILURE);
}

<span class="kw">if</span> (pid &gt; <span class="dv">0</span>)
    exit(EXIT_SUCCESS);</code></pre>
<p>Now, we will switch to the directory which contains the files needed for this daemon to run (for example in case of <code>dovecot</code> we would switch to <code>/run/dovectot</code> which contains the sockets for different mail queues). Or, we could switch to <code>/</code> (like <code>apache2</code> and <code>sshd</code> do for example) if we don’t want to change to a specific directory. Anyway, it is essential to change the current running directory to prevent cases where if the program was started in a <code>cwd</code> from a different partition that partition could no longer be <code>umount</code>ed.</p>
<pre class="sourceCode c"><code class="sourceCode c">change_dir = chdir(<span class="st">&quot;/&quot;</span>);
<span class="kw">if</span> (change_dir &lt; <span class="dv">0</span> ) {
    perror(<span class="st">&quot;chdir&quot;</span>);
    exit(EXIT_FAILURE);
}</code></pre>
<p>Though the following steps are optional, it is better to do them too to ensure a reproducible behaviour of our executable, no matter what state the system was when we started it.</p>
<p>Because a child process inherits file descriptors and file descriptors from his parent, we need to close them. We use <code>sysconf</code> to get the maximum number of opened file descriptors in order to close all of them and prevent leaks. Then, we will set <code>umask</code> to 0 to gain complete permissions over anything we write.</p>
<pre class="sourceCode c"><code class="sourceCode c">maxfd = sysconf(_SC_OPEN_MAX);
<span class="kw">if</span> (maxfd &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;sysconf _SC_OPEN_MAX&quot;</span>);
    exit(EXIT_FAILURE);
}

<span class="kw">for</span> (fd = <span class="dv">0</span>; fd &lt; maxfd; fd++)
    <span class="co">/* note that we ignore return code here */</span>
    close(fd);

umask(<span class="dv">0</span>);</code></pre>
<p>Now we should reopen the 3 standard file descriptors. We can point them to <code>/dev/null</code> or to specific log files. Here we open all of them to <code>/dev/null</code>:</p>
<pre class="sourceCode c"><code class="sourceCode c">fd = open(<span class="st">&quot;/dev/null&quot;</span>, <span class="dv">0</span>);
<span class="kw">if</span> (fd &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;open /dev/null&quot;</span>);
    exit(EXIT_FAILURE);
}

status = dup2(fd, <span class="dv">0</span>);
<span class="kw">if</span> (status &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;dup 0&quot;</span>);
    exit(EXIT_FAILURE);
}
status = dup2(fd, <span class="dv">1</span>);
<span class="kw">if</span> (status &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;dup 1&quot;</span>);
    exit(EXIT_FAILURE);
}
status = dup2(fd, <span class="dv">2</span>);
<span class="kw">if</span> (status &lt; <span class="dv">0</span>) {
    perror(<span class="st">&quot;dup 2&quot;</span>);
    exit(EXIT_FAILURE);
}</code></pre>
<p>We now, have a fully working daemon, created by us. However, certain considerations must be taken:</p>
<ol type="1">
<li>First, if our code is to be launched by <code>inetd</code> then only the <code>chdir</code> and <code>umask</code> steps are useful. No <code>fork</code> and <code>setsid</code> should be called (otherwise <code>inetd</code> will get confused) and all other steps are already done by <code>inetd</code>.</li>
<li>Second, all of the above code is already implemented in the <code>daemon</code> function call with slightly less control over the end-result. It might be easier to use it instead of all of the above steps.</li>
</ol>
<p>All is good and nice but what if we want to daemonize a normal process? Well, we can use <code>nohup</code>, <code>disown</code> or <code>start-stop-daemon</code>. Or we could resort to special services to start our daemons like <code>inetd</code> and <code>upstart</code>.</p>
</section>
<section id="using-nohup-for-daemonizing-processes" class="level3">
<h3>Using nohup for daemonizing processes</h3>
<p><code>nohup</code> is a command which is used to run a command which ignores the HUP (hangup) signal. The HUP signal is used by a terminal to warn dependent processes of logout. Thus, processes started with <code>nohup</code> won’t be killed after the <code>tty</code> is destroyed.</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">nohup</span> sleep 10000 <span class="kw">&amp;</span>
[<span class="kw">1</span>] 5470
<span class="kw">nohup</span>: ignoring input and appending output to ‘nohup.out’
$ <span class="kw">exit</span></code></pre>
<p>Now open a new terminal and</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">pgrep</span> sleep
<span class="kw">5470</span></code></pre>
<p>We can simulate <code>nohup</code> inside our C code too. Let’s configure signal handlers:</p>
<pre class="sourceCode c"><code class="sourceCode c">memset (&amp;sig_act, <span class="dv">0</span> , <span class="kw">sizeof</span>(sig_act));
<span class="co">/* Ignore SIGHUP signal */</span>
<span class="kw">if</span> (signal(SIGHUP, SIG_IGN) == SIG_ERR){
    perror(<span class="st">&quot;signal&quot;</span>);
    exit(EXIT_FAILURE);
}</code></pre>
<p>Now, if <code>stdout</code> is a terminal we have to redirect output to a file, just like the original command does:</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="kw">if</span>(isatty(fileno(stdout))) {
    rc = open (<span class="st">&quot;nohup.out&quot;</span>, O_WRONLY | O_CREAT, <span class="dv">0644</span>);
    <span class="kw">if</span> (rc &lt; <span class="dv">0</span>) {
        perror(<span class="st">&quot;open&quot;</span>);
        exit(EXIT_FAILURE);
    }
    rc = dup2(rc, STDOUT_FILENO);
    <span class="kw">if</span> (rc &lt; <span class="dv">0</span>) {
        perror(<span class="st">&quot;dup2&quot;</span>);
        exit(EXIT_FAILURE);
    }
}</code></pre>
<p>Then we can <code>fork</code> and <code>exec</code> to get to our new process.</p>
<p>Let’s test it now (<code>./a.out</code> is our test binary, it receives as arguments the command line to execute in <code>exec</code>):</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">./a.out</span> gedit <span class="kw">&amp;</span>
[<span class="kw">1</span>] 22727</code></pre>
<p>After we close the terminal and open a new one, we clearly see that the process will be adopted by <code>init</code>:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">ps</span> -ef <span class="kw">|</span> <span class="kw">grep</span> gedit
<span class="kw">matei</span>    22727     1  2 18:25 ?        00:00:01 gedit</code></pre>
</section>
<section id="disowning-a-process" class="level3">
<h3>Disowning a process</h3>
<p>What if we already started the process and forgot to use <code>nohup</code>? We can use <code>disown</code> to remove the process from the current session hierarchy, thus making it able to survive when the <code>tty</code> is closed.</p>
<p>Our first job is to use <code>^Z</code> to stop/pause the program and to go back to terminal. Then we have to use <code>bg</code> to run it in the background.</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">gedit</span>
^<span class="kw">Z</span>
[<span class="kw">1</span>]+  Stopped                 gedit
$ <span class="kw">bg</span>
[<span class="kw">1</span>]+ gedit <span class="kw">&amp;</span></code></pre>
<p>Now, we use <code>disown</code> with the <code>-h</code> option, to mark the process so that <code>SIGHUP</code> is not gonna be received. If we don’t use the <code>-h</code> option the process is also removed from the current jobs table, which is something we like to do anyway:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">disown</span></code></pre>
<p>If we go to another terminal, we should see that the process has been adopted by <code>init</code>:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">ps</span> -ef <span class="kw">|</span> <span class="kw">grep</span> gedit
<span class="kw">matei</span>    23087 22921  8 18:38 pts/6    00:00:01 gedit</code></pre>
<p>What happened? Our <code>gedit</code> process is not adopted by <code>init</code>. This is because we haven’t yet closed the terminal in which we have launched it. After closing it we have</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">ps</span> -ef <span class="kw">|</span> <span class="kw">grep</span> gedit
<span class="kw">matei</span>    12490     1  1 07:07 ?        00:00:00 gedit</code></pre>
<p>To conclude:</p>
<ul>
<li>we need to use daemons for autonomous tasks</li>
<li>we have multiple ways for creating daemons</li>
<li>we can control daemons using signals and config files</li>
</ul>
<p>All other methods will be presented in a second part article.</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Sun, 23 Mar 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/daemonizing-processes.html</guid>
</item>
<item>
    <title>Unix portability. Autoconf, Automake, Libtool</title>
    <link>http://techblog.rosedu.org/unix-auto.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/unix-auto.html" title="Unix portability. Autoconf, Automake, Libtool">Unix portability. Autoconf, Automake, Libtool</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on March  8, 2014</span>
      by
      <span class="author"><a href="/people/alexandru-goia.html">Alexandru Goia</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/unix.html">Unix</a>, <a href="/tags/c.html">C</a>, <a href="/tags/portable-code.html">portable code</a>, <a href="/tags/autoconf.html">autoconf</a>, <a href="/tags/automake.html">automake</a>, <a href="/tags/libtool.html">libtool</a></span>
      </span>

      <p>The purpose of this article is to generally present the utilities <a href="http://www.gnu.org/software/autoconf/manual/index.html" title="autoconf">Autoconf</a>, <a href="http://www.gnu.org/software/automake/manual/index.html" title="automake">Automake</a> and <a href="http://www.gnu.org/software/libtool/manual/index.html" title="libtool">Libtool</a>, which ease very much the process of installation from sources of software packages or libraries, from the point of view of users. It is assumed that the user uses any Unix/Unix-like system, and the purpose of the developer, who chooses to use these GNU tools, is to make the installation, on the user’s system, as easy as possible.</p>
<!--more-->

<p>If you are a serious Unix/Linux user, for sure you have been in the situation of compiling a program or a library from sources. Then, you called <code>./configure; make; make install</code> and you got an executable or a library. In this article, we change the point of view, assuming that we are the software’s developers and not the users, and our purpose is to understand in principle how can we generate the <code>configure</code> script and the other additional files,</p>
<p>This article aims to explain <em>le raison d’etre</em> of these very useful tools (<a href="http://www.gnu.org/software/autoconf/manual/index.html" title="autoconf">Autoconf</a>, <a href="http://www.gnu.org/software/automake/manual/index.html" title="automake">Automake</a>, <a href="http://www.gnu.org/software/libtool/manual/index.html" title="libtool">Libtool</a>) and to present generic configuration files, in the case of a simple program and the case of a simple library – thus, the base syntax for these GNU tools with the aim of creating an easy install experience for the users.</p>
<section id="the-theory" class="level3">
<h3>The Theory</h3>
<p>Autoconf is a software tool useful in the process of compilation from sources of a software package. At running time, it generates shell scripts which will run on the user’s system, independently of Autoconf version installed there (thus there is no need that the user should install this on his system too). These shell scripts will be run without manual interventions on any Unix/Posix system. Thus, Autoconf makes easier the porting of source programs on various Unix/Posix systems by determining the characteristics of the user’s system on which the compilation will take place just before this.</p>
<p>For each software package on which we run it, Autoconf generates a configuration script from a template file, named <code>configure.ac</code> or <code>configure.in</code>, which lists the options of the user’s system, options that the software package needs or uses.</p>
<p>It is being said, like Unix, that those who do not understand Autoconf are destined to reinvent it; Autoconf doesn’t make easier the life of the developer – which is supposed to be a mature one –, but it makes easy the installation experience of the software, on the Unix/Unix-like systems of the users, which are – at least a priori – various.</p>
<p>So, Autoconf solves the problem of determining the pieces of information about the system needed for compilation, right before it. It is only the first part of a larger problem which is the ‘perfect’ compilation on the user’s system, in other words, the development of portable software. Here enters the GNU Build System, which continues and completes what Autoconf started, by another two GNU tools: Automake and Libtool.</p>
<p>The <code>make</code> tool (GNU make, gmake, etc.) is present on every Unix/Unix-like system. Automake allows developers to describe in a file named <code>Makefile.am</code> the build specifications, with a syntax simpler and richer than that of a regular <code>Makefile</code>. From the file <code>Makefile.am</code>, after running Automake (<code>automake</code>), a file named <code>Makefile.in</code> will be generated, which in turn will be used by the <code>configure</code> script to generate on the user’s system the classic file <code>Makefile</code>. Automake is very useful in the situation of software packages with multiple subdirectories or with multiple sources, but even for simple programs the reached portability is a gain.</p>
<p>Sometimes, we don’t want to generate only executables, we want to also generate libraries, in order to let them be further used by other developers. We want to generate shared (dynamic) libraries, and do this in a portable way. This is the task of the Libtool tool. One of the most used features of Libtool is the coexistence of multiple versions of a library, so the user may install or upgrade the library, without destroying the binary compatibility. Libtool is used by default by Automake, when we want to generate dynamic libraries, and there is no need to know its syntax.</p>
<p>These GNU tools are based on the macro-preprocessor GNU M4, but in this article we will not talk about it.</p>
</section>
<section id="the-practice" class="level3">
<h3>The Practice</h3>
<p>A <code>configure.ac</code> file has the following structure:</p>
<pre class="configure"><code>autoconf requirements
AC_INIT(package, version, [bug-report-email], [tarname], [url])
information on the package
checks for programs
checks for libraries
checks for header files
checks for types
checks for structures
checks for compiler characteristics
checks for library functions
checks for system services
AC_CONFIG_FILES([file...])
AC_OUTPUT</code></pre>
<p>For example, for a simple project, <code>configure.ac</code>/<code>configure.in</code> can look like this (comments inline for each directive):</p>
<pre class="configure"><code>dnl Comments start with dnl
dnl This file will be processed with autoconf command, in order to
dnl generate the configure script

AC_INIT([hello], [1.0])
dnl Do not put spaces between AC_* / AM_* and the open paranthesis!
dnl AC_* : declarations for Autoconf
dnl AM_* : declarations for Automake

AM_INIT_AUTOMAKE([-Wall -Werrror foreign])
dnl for Automake, in order to create Makefile.in
dnl -Wall -Werror request Automake to activate warnings
dnl and to report them as errors (Automake warnings, not compiler
dnl warnings).

dnl If in a configure.in file there is an AM_* directive then
dnl Autoconf will automatically call Automake.

dnl foreign specifies the program does not adhere to
dnl the GNU standard: there are not ChangeLog, AUTHORS, NEWS and
dnl README files.

dnl We determine the standardized name of the machine
AC_CANONICAL_HOST
dnl for Linux on Intel 32-bit this is i686-pc-linux-gnu

AC_LANG_C
dnl or AC_LANG([C])
dnl specifies the C language as the programming language
dnl or AC_LANG([C++]) or AC_LANG_CPLUSPLUS for C++ language

AC_PROG_CC
dnl verifies the existence of the C compiler
AC_PROG_CXX
dnl verifies the existence of the C++ compiler
dnl insert it if the sources are written in the C++ language

AC_PROG_MAKE_SET
dnl verifies the existence of make program

AC_HEADER_STDC
dnl verifies the existence of standard C files

AC_CHECK_HEADERS([stdio.h])
dnl verifies the existence of header file stdio.h

AC_CONFIG_HEADERS([config.h])
dnl the configure script will generate at runtime the config.h file
dnl which will contain useful #define directives for the program.

dnl config.h can be big enough, because every feature tested on
dnl the user&#39;s system is added as a #define in config.h

AC_CONFIG_FILES([
   Makefile
   src/Makefile
])
dnl AC_CONFIG_FILES declares the list of files that will be
dnl generated from their templates with .in extension

AC_OUTPUT
dnl the ending line, which produces a sequence of commands
dnl in the configure script, a sequence that will generate
dnl the registered files from AC_CONFIG_HEADERS and 
dnl AC_CONFIG_FILES</code></pre>
<p>Of course, the <code>configure.in</code> file can be much more complex, with many <code>AC_*</code> and <code>AM_*</code> lines. For this, we recommend the Autoconf manual.</p>
<p>We should also have <code>Makefile.am</code> files in every subdirectory in the source tree. For example, for a tree with few source files (<code>hello</code> program with sources: <code>main.c</code> and <code>functions.c</code>):</p>
<pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="co"># src/Makefile.am</span>
<span class="dt">bin_PROGRAMS </span><span class="ch">=</span><span class="st"> hello</span>
<span class="dt">hello_SOURCES </span><span class="ch">=</span><span class="st"> main.c functions.c</span></code></pre>
<p>If the sources of the program contain an <code>./include/</code> directory which has header files then <code>Makefile.am</code> file from that directory must also contain this line:</p>
<pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="co"># include/Makefile.am</span>
<span class="dt">include_HEADERS</span><span class="ch">=</span><span class="st">header1.h header2.h header3.h ... headerN.h</span></code></pre>
<p>In the <code>Makefile.am</code> from the root directory we must have the following line:</p>
<pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dt">SUBDIRS </span><span class="ch">=</span><span class="st"> doc src</span></code></pre>
<p>or</p>
<pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="dt">SUBDIRS </span><span class="ch">=</span><span class="st"> src</span></code></pre>
<p><code>SUBDIRS</code> is a special variable which lists all directories in which <code>make</code> will enter, before processing the current directory.</p>
<p>In the case of a simple library, the <code>Makefile.am</code> from the respective directory will look like this:</p>
<pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="co"># lib/Makefile.am</span>
<span class="dt">lib_LTLIBRARIES </span><span class="ch">=</span><span class="st"> libaa.la</span>
<span class="dt">libaa_la_SOURCES </span><span class="ch">=</span><span class="st"> library-aa.c</span></code></pre>
<p>We will run the command <code>libtoolize</code>, after which two new files will be created: <code>ltconfig</code> and <code>ltmain.sh</code>.</p>
<p>For <code>configure.in</code> and <code>Makefile.am</code>, we will run the commands <code>aclocal</code>, <code>autoconf</code>, and, then, <code>automake</code>.</p>
<p>Also, the source code, which must be portable, must “fold” on these tools.</p>
</section>
<section id="examples" class="level3">
<h3>Examples</h3>
<ol type="1">
<li>This examples checks if <code>ncurses</code> is installed and saves the name of the terminal inside the <code>s</code> variable (if <code>ncurses</code> is installed then the name can be obtained by running <code>termname</code>, otherwise a constant value of <code>TERM</code> is used):</li>
</ol>
<pre class="configure"><code>#include &quot;config.h&quot;
...
#ifdef HAVE_NCURSES
strcpy(s, termname());
#else
strcpy(s, getenv(&quot;TERM&quot;));
#endif // HAVE_NCURSES</code></pre>
<ol start="2" type="1">
<li>This example checks and includes the proper header for string functions, if there is one:</li>
</ol>
<pre class="configure"><code>#include &quot;config.h&quot;
...
#ifdef HAVE_STRING_H
#include &lt;string.h&gt;
#else
#ifdef HAVE_STRINGS_H
#include &lt;strings.h&gt;
#endif
#endif</code></pre>
</section>
<section id="bibliography.-conclusions" class="level3">
<h3>Bibliography. Conclusions</h3>
<p>For more informations, we recommend the free online book <a href="http://www.sourceware.org/autobook" title="GNU Autoconf, Automake and Libtool">GNU Autoconf, Automake and Libtool</a>, and also <a href="https://www.lrde.epita.fr/~adl/dl/autotools.pdf" title="Using GNU Autotools">Using GNU Autotools</a>, from <a href="https://www.lrde.epita.fr/~adl/autotools.html" title="Autotools">the page of Alexandre Duret-Lutz</a>.</p>
<p>After this article, we wish that the young Unix/Unix-like/Linux programmers are aware of the existence of these tools, and have them in mind when they will have to develop open-source programs which are intended to be portable across all Unix systems.</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Sat, 08 Mar 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/unix-auto.html</guid>
</item>
<item>
    <title>A superficial exploration of Haskell, part 2: Lazy by default</title>
    <link>http://techblog.rosedu.org/haskell-part2.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/haskell-part2.html" title="A superficial exploration of Haskell, part 2: Lazy by default">A superficial exploration of Haskell, part 2: Lazy by default</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on March  2, 2014</span>
      by
      <span class="author"><a href="/people/dan-serban.html">Dan Șerban</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/haskell.html">haskell</a></span>
      </span>

      <p>Haskell uses lazy evaluation by default, but what does that mean exactly?</p>
<p>We’re going to state the abstract definition of laziness, behold its nonsensical beauty for a few seconds, and then conclude that a concrete example is necessary in order to understand the concept:</p>
<blockquote>
<p>Laziness is the separation of equation from execution.</p>
</blockquote>
<!--more-->

<p>Before we look at an example, let me remind you of a bit of syntactic sugar that Haskell provides in order to quickly define a list of successive integers:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: [<span class="dv">20</span><span class="fu">..</span><span class="dv">70</span>]
[<span class="dv">20</span>,<span class="dv">21</span>,<span class="dv">22</span>,<span class="dv">23</span>,<span class="dv">24</span>,<span class="dv">25</span>,<span class="dv">26</span>,<span class="dv">27</span>,<span class="dv">28</span>,<span class="dv">29</span>,<span class="dv">30</span>,<span class="dv">31</span>,<span class="dv">32</span>,<span class="dv">33</span>,<span class="dv">34</span>,<span class="dv">35</span>,<span class="dv">36</span>,<span class="dv">37</span>,<span class="dv">38</span>,<span class="dv">39</span>,<span class="dv">40</span>,<span class="dv">41</span>,<span class="dv">42</span>,<span class="dv">43</span>,<span class="dv">44</span>,<span class="dv">45</span>,<span class="dv">46</span>,<span class="dv">47</span>,<span class="dv">48</span>,<span class="dv">49</span>,<span class="dv">50</span>,<span class="dv">51</span>,<span class="dv">52</span>,<span class="dv">53</span>,<span class="dv">54</span>,<span class="dv">55</span>,<span class="dv">56</span>,<span class="dv">57</span>,<span class="dv">58</span>,<span class="dv">59</span>,<span class="dv">60</span>,<span class="dv">61</span>,<span class="dv">62</span>,<span class="dv">63</span>,<span class="dv">64</span>,<span class="dv">65</span>,<span class="dv">66</span>,<span class="dv">67</span>,<span class="dv">68</span>,<span class="dv">69</span>,<span class="dv">70</span>]</code></pre>
<p>As you might remember from <a href="http://techblog.rosedu.org/haskell-part1.html">part 1</a>, <code>λ:</code> is my custom GHCi prompt, so we’re effectively looking at the result of how GHCi interprets the notation <code>[20..70]</code>.</p>
<p>OK then. To start, let’s define two lists:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="kw">let</span> list1 <span class="fu">=</span> [<span class="dv">20</span><span class="fu">..</span><span class="dv">70</span>]
λ: <span class="kw">let</span> list2 <span class="fu">=</span> map (<span class="fu">+</span><span class="dv">1</span>) list1</code></pre>
<p>At this point you might be thinking “Oh look, <code>list1</code> is the enumeration of all integers between 20 and 70, and <code>list2</code> is the enumeration of all integers between 21 and 71”.</p>
<p><strong>Well, no.</strong> Not yet, at least.</p>
<p>GHCi provides a command called <code>:sprint</code> that allows us to take a peek at how far along the evaluation of a given expression has progressed.</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="fu">:</span>sprint list1
list1 <span class="fu">=</span> _
λ: <span class="fu">:</span>sprint list2
list2 <span class="fu">=</span> _</code></pre>
<p>So what <code>:sprint</code> is telling us in the above snippet is that both <code>list1</code> and <code>list2</code> are unevaluated at this point. To establish some terminology, an underscore in the context of <code>:sprint</code> output represents a <strong>thunk</strong>. Formally defined, a thunk is an expression that hasn’t yet been evaluated. You may think of it as a value wrapped in a function of zero arguments. When the function is called, the value springs into existence.</p>
<p>We are now going to ask increasingly “intrusive” questions about <code>list2</code> and then each step along the way examine what has been evaluated and what hasn’t.</p>
<p>The simplest and least intrusive question we can ask about a list is whether or not it’s empty.</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: null list2
<span class="dt">False</span>
λ: <span class="fu">:</span>sprint list1
list1 <span class="fu">=</span> <span class="dv">20</span> <span class="fu">:</span> _
λ: <span class="fu">:</span>sprint list2
list2 <span class="fu">=</span> _ <span class="fu">:</span> _</code></pre>
<p>In order to answer that question, GHCi needs to know whether or not the first element exists, and as a result, <code>list2</code> is no longer unevaluated, it is now partially evaluated. GHCi now knows something about the structure of <code>list2</code> - it knows that it consists of something “consed onto” (prepended to) something else. In the next round, that “something” will turn out to be the value <code>21</code>, but for right now this fact is irrelevant to the process of answering the question “is <code>list2</code> empty”. However, we notice the value <code>20</code> is fully evaluated as the head of <code>list1</code> - this particular evaluation was necessary in order to construct the thunk <code>(+1) 20</code>.</p>
<p>Next, we ask for the first element of <code>list2</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: head list2
<span class="dv">21</span>
λ: <span class="fu">:</span>sprint list1
list1 <span class="fu">=</span> <span class="dv">20</span> <span class="fu">:</span> _
λ: <span class="fu">:</span>sprint list2
list2 <span class="fu">=</span> <span class="dv">21</span> <span class="fu">:</span> _</code></pre>
<p>We notice that the expression <code>(+1) 20</code> mentioned above is now fully evaluated and therefore no longer a thunk.</p>
<p>Next, let’s ask for the first 5 elements of <code>list2</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: take <span class="dv">5</span> list2
[<span class="dv">21</span>,<span class="dv">22</span>,<span class="dv">23</span>,<span class="dv">24</span>,<span class="dv">25</span>]
λ: <span class="fu">:</span>sprint list1
list1 <span class="fu">=</span> <span class="dv">20</span> <span class="fu">:</span> <span class="dv">21</span> <span class="fu">:</span> <span class="dv">22</span> <span class="fu">:</span> <span class="dv">23</span> <span class="fu">:</span> <span class="dv">24</span> <span class="fu">:</span> _
λ: <span class="fu">:</span>sprint list2
list2 <span class="fu">=</span> <span class="dv">21</span> <span class="fu">:</span> <span class="dv">22</span> <span class="fu">:</span> <span class="dv">23</span> <span class="fu">:</span> <span class="dv">24</span> <span class="fu">:</span> <span class="dv">25</span> <span class="fu">:</span> _</code></pre>
<p>Next, let’s ask for the 18th element of <code>list2</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: list2 <span class="fu">!!</span> <span class="dv">17</span>
<span class="dv">38</span>
λ: <span class="fu">:</span>sprint list1
list1 <span class="fu">=</span> <span class="dv">20</span> <span class="fu">:</span> <span class="dv">21</span> <span class="fu">:</span> <span class="dv">22</span> <span class="fu">:</span> <span class="dv">23</span> <span class="fu">:</span> <span class="dv">24</span> <span class="fu">:</span> <span class="dv">25</span> <span class="fu">:</span> <span class="dv">26</span> <span class="fu">:</span> <span class="dv">27</span> <span class="fu">:</span> <span class="dv">28</span> <span class="fu">:</span> <span class="dv">29</span> <span class="fu">:</span>
        <span class="dv">30</span> <span class="fu">:</span> <span class="dv">31</span> <span class="fu">:</span> <span class="dv">32</span> <span class="fu">:</span> <span class="dv">33</span> <span class="fu">:</span> <span class="dv">34</span> <span class="fu">:</span> <span class="dv">35</span> <span class="fu">:</span> <span class="dv">36</span> <span class="fu">:</span> <span class="dv">37</span> <span class="fu">:</span> _
λ: <span class="fu">:</span>sprint list2
list2 <span class="fu">=</span> <span class="dv">21</span> <span class="fu">:</span> <span class="dv">22</span> <span class="fu">:</span> <span class="dv">23</span> <span class="fu">:</span> <span class="dv">24</span> <span class="fu">:</span> <span class="dv">25</span> <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span>
        _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> _ <span class="fu">:</span> <span class="dv">38</span> <span class="fu">:</span> _</code></pre>
<p>Now this is interesting.</p>
<p>Elements from the 6th to the 17th are fully evaluated in <code>list1</code> but unevaluated in <code>list2</code>. Because of how <code>list1</code> is defined, it is going to be evaluated in small, close-proximity increments from left to right. But all values in <code>list2</code> are evaluated by applying a transformation on elements in the corresponding positions in <code>list1</code>. That is why we are starting to see gaps in <code>list2</code>.</p>
<p>This example really drives home the essence of lazy evaluation. By default, Haskell will evaluate as little as possible, as late as possible. This is in contrast to traditional, imperative programming languages which evaluate as much as possible, as soon as possible.</p>
<p>Next, let’s ask for the length of <code>list2</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: length list2
<span class="dv">51</span>
λ: <span class="fu">:</span>sprint list1
list1 <span class="fu">=</span> [<span class="dv">20</span>,<span class="dv">21</span>,<span class="dv">22</span>,<span class="dv">23</span>,<span class="dv">24</span>,<span class="dv">25</span>,<span class="dv">26</span>,<span class="dv">27</span>,<span class="dv">28</span>,<span class="dv">29</span>,
         <span class="dv">30</span>,<span class="dv">31</span>,<span class="dv">32</span>,<span class="dv">33</span>,<span class="dv">34</span>,<span class="dv">35</span>,<span class="dv">36</span>,<span class="dv">37</span>,<span class="dv">38</span>,<span class="dv">39</span>,
         <span class="dv">40</span>,<span class="dv">41</span>,<span class="dv">42</span>,<span class="dv">43</span>,<span class="dv">44</span>,<span class="dv">45</span>,<span class="dv">46</span>,<span class="dv">47</span>,<span class="dv">48</span>,<span class="dv">49</span>,
         <span class="dv">50</span>,<span class="dv">51</span>,<span class="dv">52</span>,<span class="dv">53</span>,<span class="dv">54</span>,<span class="dv">55</span>,<span class="dv">56</span>,<span class="dv">57</span>,<span class="dv">58</span>,<span class="dv">59</span>,
         <span class="dv">60</span>,<span class="dv">61</span>,<span class="dv">62</span>,<span class="dv">63</span>,<span class="dv">64</span>,<span class="dv">65</span>,<span class="dv">66</span>,<span class="dv">67</span>,<span class="dv">68</span>,<span class="dv">69</span>,<span class="dv">70</span>]
λ: <span class="fu">:</span>sprint list2
list2 <span class="fu">=</span> [<span class="dv">21</span>,<span class="dv">22</span>,<span class="dv">23</span>,<span class="dv">24</span>,<span class="dv">25</span>,_,_,_,_,_,
         _,_,_,_,_,_,_,<span class="dv">38</span>,_,_,
         _,_,_,_,_,_,_,_,_,_,
         _,_,_,_,_,_,_,_,_,_,
         _,_,_,_,_,_,_,_,_,_,_]</code></pre>
<p>At this point, <code>list1</code> is fully evaluated because there are no two ways around it - in order to compute the length of <code>list2</code>, GHCi needs to keep track of each and every one of its thunks, therefore it needs to generate the entire “spine” of the list. The process of generating the thunks <code>(+1) 25</code> through <code>(+1) 70</code> will require all elements of <code>list1</code> to be fully evaluated.</p>
<p>Finally, there is only one thing left for us to do such that <code>list2</code> is fully evaluated too - compute the sum of its elements:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: sum list2
<span class="dv">2346</span>
λ: <span class="fu">:</span>sprint list2
list2 <span class="fu">=</span> [<span class="dv">21</span>,<span class="dv">22</span>,<span class="dv">23</span>,<span class="dv">24</span>,<span class="dv">25</span>,<span class="dv">26</span>,<span class="dv">27</span>,<span class="dv">28</span>,<span class="dv">29</span>,<span class="dv">30</span>,
         <span class="dv">31</span>,<span class="dv">32</span>,<span class="dv">33</span>,<span class="dv">34</span>,<span class="dv">35</span>,<span class="dv">36</span>,<span class="dv">37</span>,<span class="dv">38</span>,<span class="dv">39</span>,<span class="dv">40</span>,
         <span class="dv">41</span>,<span class="dv">42</span>,<span class="dv">43</span>,<span class="dv">44</span>,<span class="dv">45</span>,<span class="dv">46</span>,<span class="dv">47</span>,<span class="dv">48</span>,<span class="dv">49</span>,<span class="dv">50</span>,
         <span class="dv">51</span>,<span class="dv">52</span>,<span class="dv">53</span>,<span class="dv">54</span>,<span class="dv">55</span>,<span class="dv">56</span>,<span class="dv">57</span>,<span class="dv">58</span>,<span class="dv">59</span>,<span class="dv">60</span>,
         <span class="dv">61</span>,<span class="dv">62</span>,<span class="dv">63</span>,<span class="dv">64</span>,<span class="dv">65</span>,<span class="dv">66</span>,<span class="dv">67</span>,<span class="dv">68</span>,<span class="dv">69</span>,<span class="dv">70</span>,<span class="dv">71</span>]</code></pre>
<section id="conclusion" class="level3">
<h3>Conclusion</h3>
<p>Laziness can be a tremendously helpful device for designing Haskell programs that run in constant space and feature a clean separation of pure code vs. side-effecting code. However, care must be taken to avoid what is known as “space leaks”, which we are going to cover in the next instalment of this series.</p>
</section>
<section id="editorial-note" class="level3">
<h3>Editorial note</h3>
<p>This blog post was inspired by chapter 2 of Simon Marlow’s excellent book <a href="http://chimera.labs.oreilly.com/books/1230000000929">“Parallel and Concurrent Programming in Haskell”</a> which is available both in e-book format as well as free of charge online.</p>
</section>
<section id="update" class="level3">
<h3>Update</h3>
<p>In recent versions of GHC, due to the <code>Monomorphism Restriction</code> being off by default (in contrast with the current ones) some of the examples might look a little different. See <a href="http://www.reddit.com/r/haskell/comments/1zfz5m/a_superficial_exploration_of_haskell_part_2_lazy/">the discussion on twitter</a>.</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Sun, 02 Mar 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/haskell-part2.html</guid>
</item>
<item>
    <title>Unix standards and implementations. Unix portability</title>
    <link>http://techblog.rosedu.org/unix-standards.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/unix-standards.html" title="Unix standards and implementations. Unix portability">Unix standards and implementations. Unix portability</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on February  2, 2014</span>
      by
      <span class="author"><a href="/people/alexandru-goia.html">Alexandru Goia</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/unix.html">Unix</a>, <a href="/tags/c.html">C</a>, <a href="/tags/portable-code.html">portable code</a>, <a href="/tags/posix.html">POSIX</a>, <a href="/tags/sus.html">SUS</a>, <a href="/tags/libc.html">libc</a></span>
      </span>

      <p>The purpose of this article is to present in a general way the Unix standards and how can we write portable code on Unix systems, not only on Linux ones.</p>
<!--more-->

<p>In the Unix world at present, there are three important standards:</p>
<ul>
<li>the C language (ISO C standard) and the standard C library (<code>libc</code>), which are included in the POSIX standard</li>
<li>the POSIX standard (<em>P</em>ortable <em>O</em>perating <em>S</em>ystem <em>I</em>nterface for Uni<em>x</em>), which has the last version from 2008</li>
<li>the SUS standard (<em>S</em>ingle <em>U</em>nix <em>S</em>pecification), which includes as a subset the POSIX standard, with the last version from 2010 (SUSv4).</li>
</ul>
<p>The POSIX standard consists of:</p>
<ul>
<li>POSIX.1: core services</li>
<li>POSIX.1b: real-time extensions</li>
<li>POSIX.1c: threads extensions</li>
<li>POSIX.2: shell and utilities</li>
</ul>
<p>We will be interested in this article only by POSIX.1 (last version: POSIX.1-2008, or IEEE Std 1003.1-2008) from the whole POSIX standard.</p>
<p>As implementations of the standard, we can name the GNU/Linux-based operating systems, the systems which descend from the BSD Unix version: FreeBSD, NetBSD, OpenBSD, DragonflyBSD, the certified and commercial UNIX-es, based on UNIX System V release 4 and, from case to case, with BSD elements: Oracle Solaris (known previously as Sun Solaris), HP-UX and Tru64 UNIX (HP), AIX (IBM), IRIX (SGI), Unixware and OpenServer (SCO), and also Mac OS X, which is also officially certified as a UNIX system, based on FreeBSD elements and not on UNIX System V.</p>
<p>The most “popular” Unix systems are at present Linux, FreeBSD, Solaris and Mac OS X. With regards to the C language, all these operating systems (Linux 3.x, FreeBSD &gt;= 8.0, Mac OS X &gt;= 10.6.8, Solaris &gt;= 10) support the following LIB C headers:</p>
<ul>
<li><code>assert.h</code>: verify program assertion</li>
<li><code>complex.h</code>: complex arithmetic support</li>
<li><code>ctype.h</code>: character classification and mapping support</li>
<li><code>errno.h</code>: error codes</li>
<li><code>fenv.h</code>: floating-point environment</li>
<li><code>float.h</code>: floating-point constants and characteristics</li>
<li><code>inttypes.h</code>: integer type format conversion</li>
<li><code>iso646.h</code>: macros for assignment, relational, and unary operators</li>
<li><code>limits.h</code>: implementation constants</li>
<li><code>locale.h</code>: locale categories and related definitions</li>
<li><code>math.h</code>: mathematical functions and type declarations and constants</li>
<li><code>setjmp.h</code>: nonlocal <code>goto</code></li>
<li><code>signal.h</code>: signals</li>
<li><code>stdarg.h</code>: variable argument lists</li>
<li><code>stdbool.h</code>: boolean type and values</li>
<li><code>stddef.h</code>: standard definitions</li>
<li><code>stdint.h</code>: integer types</li>
<li><code>stdio.h</code>: standard I/O library</li>
<li><code>stdlib.h</code>: utility functions</li>
<li><code>string.h</code>: string operations</li>
<li><code>tgmath.h</code>: type-generic math macros</li>
<li><code>time.h</code>: time and date</li>
<li><code>wchar.h</code>: extended multibyte and wide character support</li>
<li><code>wctype.h</code>: wide character classification and mapping support</li>
</ul>
<p>They also support the following POSIX headers (in the C language):</p>
<ul>
<li><code>aio.h</code>: asynchronous I/O</li>
<li><code>cpio.h</code>: cpio archive values</li>
<li><code>dirent.h</code>: directory entries</li>
<li><code>dlfcn.h</code>: dynamic linking</li>
<li><code>fcntl.h</code>: file control</li>
<li><code>fnmatch.h</code>: filename-matching types</li>
<li><code>glob.h</code>: pathname pattern-matching and generations</li>
<li><code>grp.h</code>: group file</li>
<li><code>iconv.h</code>: codeset conversion utility</li>
<li><code>langinfo.h</code>: language information constants</li>
<li><code>monetary.h</code>: monetary types and functions</li>
<li><code>netdb.h</code>: network database operations</li>
<li><code>nl_types.h</code>: message catalogs</li>
<li><code>poll.h</code>: <code>poll()</code> function</li>
<li><code>pthread.h</code>: threads</li>
<li><code>pwd.h</code>: password file</li>
<li><code>regex.h</code>: regular expressions</li>
<li><code>sched.h</code>: execution scheduling</li>
<li><code>semaphore.h</code>: semaphores</li>
<li><code>strings.h</code>: string operations</li>
<li><code>tar.h</code>: tar archive values</li>
<li><code>termios.h</code>: terminal I/O</li>
<li><code>unistd.h</code>: symbolic constants</li>
<li><code>wordexp.h</code>: word-expansion definitions</li>
<li><code>arpa/inet.h</code>: Internet definitions</li>
<li><code>net/if.h</code>: socket local interfaces</li>
<li><code>netinet/in.h</code>: Internet address family</li>
<li><code>netinet/tcp.h</code>: TCP definitions</li>
<li><code>sys/mman.h</code>: memory management declarations</li>
<li><code>sys/select.h</code>: <code>select()</code> function</li>
<li><code>sys/socket.h</code>: sockets interface</li>
<li><code>sys/stat.h</code>: file status</li>
<li><code>sys/statvfs.h</code>: file system information</li>
<li><code>sys/times.h</code>: process times</li>
<li><code>sys/types.h</code>: primitive system data types</li>
<li><code>sys/un.h</code>: UNIX domain socket definitions</li>
<li><code>sys/utsname.h</code>: system name</li>
<li><code>sys/wait.h</code>: process control</li>
<li><code>fmtmsg.h</code>: message display structures</li>
<li><code>ftw.h</code>: file tree walking</li>
<li><code>libgen.h</code>: pathname management functions</li>
<li><code>ndbm.h</code>: database operations (<em>exception: Linux</em>)</li>
<li><code>search.h</code>: search tables</li>
<li><code>syslog.h</code>: system error logging</li>
<li><code>utmpx.h</code>: user accounting database (<em>exception: FreeBSD</em>)</li>
<li><code>sys/ipc.h</code>: inter-processes communication</li>
<li><code>sys/msg.h</code>: XSI message queues</li>
<li><code>sys/resource.h</code>: resource operations</li>
<li><code>sys/sem.h</code>: XSI semaphores</li>
<li><code>sys/shm.h</code>: XSI shared memory</li>
<li><code>sys/time.h</code>: time types</li>
<li><code>sys/uio.h</code>: vector I/O operations</li>
<li><code>mqueue.h</code>: message queues (exception: Mac OS X)</li>
<li><code>spawn.h</code>: real-time spawn interface.</li>
</ul>
<p>The SUS standard (the whole set of UNIX functions and constants) can be found online for <a href="http://www.unix.org/version2/" title="SUSv2">SUSv2</a> (year 1997, naming UNIX 98), <a href="http://www.unix.org/version3/" title="SUSv3">SUSv3</a> (year 2001-2002, naming UNIX 03) and <a href="http://www.unix.org/version4/" title="SUSv4">SUSv4</a> (year 2010):</p>
<p>To write portable code which can be executed on any Unix systems we must know the C headers (defined by LIBC and by POSIX) which are recognized by the Unix systems. We can activate the operating system in order to use only POSIX.1 elements, or also SUSv1, SUSv2, SUSv3, or SUSv4 using the so-called “feature test macros”:</p>
<ul>
<li><code>_POSIX_SOURCE</code> and <code>_POSIX_C_SOURCE</code>, to activate POSIX functionality</li>
<li><code>_XOPEN_SOURCE</code>, which activates SUSv1/2/3/4 functionality.</li>
</ul>
<p>For older POSIX functionality we have to declare the following in our source file:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#define _POSIX_SOURCE</span>
<span class="ot">#define _POSIX_C_SOURCE 1 </span><span class="co">/* for POSIX 1990 */</span>
<span class="co">/* use 2 for POSIX C bindings 1003.2-1992 */</span></code></pre>
<p>For POSIX 2008 functionality, we define:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#define _POSIX_SOURCE</span>
<span class="ot">#define _POSIX_C_SOURCE 200809L</span></code></pre>
<p>Or, we can compile with:</p>
<pre><code>cc -D_POSIX_SOURCE -D_POSIX_C_SOURCE=200809L filename.c</code></pre>
<p>If our code is written, or it will run on UNIX certified systems (hence on systems who follow SUSv1, SUSv2, SUSv3, or SUSv4), we must define also <code>_XOPEN_SOURCE</code>:</p>
<p>Thus, we would have to use</p>
<ul>
<li>for SUSv1:</li>
</ul>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#define _POSIX_SOURCE</span>
<span class="ot">#define _POSIX_C_SOURCE 2</span>
<span class="ot">#define _XOPEN_SOURCE</span>
<span class="ot">#define _XOPEN_SOURCE_EXTENDED 1</span></code></pre>
<ul>
<li>for SUSv2:</li>
</ul>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#define _POSIX_SOURCE</span>
<span class="ot">#define _POSIX_C_SOURCE 199506L</span>
<span class="ot">#define _XOPEN_SOURCE 500</span></code></pre>
<ul>
<li>for SUSv3:</li>
</ul>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#define _POSIX_SOURCE</span>
<span class="ot">#define _POSIX_C_SOURCE 200112L</span>
<span class="ot">#define _XOPEN_SOURCE 600</span></code></pre>
<ul>
<li>for SUSv4:</li>
</ul>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#define _POSIX_SOURCE</span>
<span class="ot">#define _POSIX_C_SOURCE 200809L</span>
<span class="ot">#define _XOPEN_SOURCE 700</span></code></pre>
<p>If we write code only for Linux platforms, we will use the feature test macro <code>_GNU_SOURCE</code>, which will activate GNU LIBC functionality, which sometimes isn’t POSIX compatible. There is also the feature test macro <code>_SVID_SOURCE</code> (to activate System V functionality) and <code>_BSD_SOURCE</code> (to activate BSD functionality). One important note is that a UNIX system (which follows SUSvX) can be activated to offer any SUSvX functionality.</p>
<p>This is the way we can write Unix portable code. Other methods to find out more about the operating system on which we compile are:</p>
<ul>
<li>LIBC functions: <code>sysconf(3)</code>, <code>pathconf(3)</code>, <code>fpathconf(3)</code> – functions which determine system constants</li>
<li><code>autoconf</code>, <code>automake</code> and <code>libtool</code>: utilities which determine at compile time, with scripts, what system and libc functions the operating system offers. (These will be part of the content of a following article.)</li>
</ul>
<p>Happy Unix programming!</p>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Sun, 02 Feb 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/unix-standards.html</guid>
</item>
<item>
    <title>Lambda Functions in C++</title>
    <link>http://techblog.rosedu.org/lambda-cpp.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/lambda-cpp.html" title="Lambda Functions in C++">Lambda Functions in C++</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on January 28, 2014</span>
      by
      <span class="author"><a href="/people/madalina-andreea-grosu.html">Mădălina-Andreea Grosu</a>, <a href="/people/matei-oprea.html">Matei Oprea</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/lambda.html">lambda</a>, <a href="/tags/higher-order-functions.html">higher-order functions</a>, <a href="/tags/c%2B%2B.html">c++</a></span>
      </span>

      <p>The C++ 2011 standard introduced the lambda expression syntax element causing some people ask <a href="http://stackoverflow.com/questions/7627098/what-is-a-lambda-expression-in-c11" title="What is a lambda expression in C++?">why it was needed</a>. In reality, it was not a new use case, people have been using this under different names since C was created. You had functors (C++ terminology) and pointer to functions for example. A basic use case was in applying the same transform over all elements of a collection (the functor’s widely shared example) or sorting elements of a vector (via <code>qsort</code> in C). But, in reality, all of these cases can be reduced to using <em>higher-order functions</em>.</p>
<!--more-->

<section id="higher-order-functions" class="level3">
<h3>1. Higher-order functions</h3>
<p>A high-order function is a function that takes one or more functions as an input and outputs a function. For example, we can use this higher-order functions to map, filter, fold and sort lists.</p>
<p>Let’s start with a simple example of a high-order function, in Haskell:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">zipWith1 ::</span> (a <span class="ot">-&gt;</span> b <span class="ot">-&gt;</span> c) <span class="ot">-&gt;</span> [a] <span class="ot">-&gt;</span> [b] <span class="ot">-&gt;</span> [c]
zipWith1 _ [] _ <span class="fu">=</span> []
zipWith1 _ _ [] <span class="fu">=</span> []
zipWith1 f (x<span class="fu">:</span>xs) (y<span class="fu">:</span>ys) <span class="fu">=</span> f x y <span class="fu">:</span> zipWith1 f xs ys</code></pre>
<p>This function will take a function and two lists as parameters and then joins them by applying the function between corresponding elements. Let’s see a little demonstration for the function written above:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">ghci<span class="fu">&gt;</span> zipWith1 (<span class="fu">+</span>) [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>] [<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>]
[<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">10</span>,<span class="dv">12</span>]</code></pre>
<p>So we found out what a <a href="http://learnyouahaskell.com/higher-order-functions" title="Learn You A Haskell">higher-order function is</a>. Now, what is a lambda function? The term comes from the Lambda Calculus and refers to anonymous functions in programming. With a lambda function you can write quick functions without naming them.</p>
<p>Let’s see the above function written using lambdas:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">zipWith (\x y <span class="ot">-&gt;</span> x <span class="fu">+</span> y ) [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>] [<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>]</code></pre>
<p>If we run this function in GHCi the result will be the same as above:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="dt">Prelude</span><span class="fu">&gt;</span> zipWith (\x y <span class="ot">-&gt;</span> x <span class="fu">+</span> y ) [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>] [<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>]
[<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">10</span>,<span class="dv">12</span>]</code></pre>
<p>Now, to see the equivalence, the following functions are one and the same:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">f x y <span class="fu">=</span> x <span class="fu">+</span> y
f x <span class="fu">=</span> \y <span class="ot">-&gt;</span> x <span class="fu">+</span> y
f <span class="fu">=</span> \x y <span class="ot">-&gt;</span> x <span class="fu">+</span> y</code></pre>
<p>Now, we know what is a lambda function and a higher-order function. Let’s see how can we use lambda functions in C++.</p>
</section>
<section id="lambdas-in-c" class="level3">
<h3>2. Lambdas in C++</h3>
<p>A lambda function, in C++, starts with <code>[</code> and it has a specific syntax:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">[capture] (params) -&gt; return_type { function_body }</code></pre>
<p>Let’s see a short example of a lambda function in C++:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp">[](<span class="dt">int</span> x, <span class="dt">int</span> y) -&gt; <span class="dt">int</span> { <span class="kw">return</span> x * y; }</code></pre>
<p>This function simply multiplies two integers.</p>
<p>Consider now the following Haskell example of applying a function to a list, using <code>map</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">map (\x <span class="ot">-&gt;</span> x <span class="fu">+</span> <span class="dv">1</span>) [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]</code></pre>
<p>In C++, we have the <a href="http://www.cplusplus.com/reference/algorithm/transform/" title="Function transform">function transform</a> which does the same thing as the <code>map</code> function from Haskell:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;iostream&gt;</span>
<span class="ot">#include &lt;algorithm&gt;</span>
<span class="ot">#include &lt;vector&gt;</span>

<span class="kw">using</span> <span class="kw">namespace</span> std;

<span class="dt">int</span> main (){
    <span class="co">/* declare 2 vectors */</span>
    vector &lt;<span class="dt">int</span>&gt; vector1;
    vector &lt;<span class="dt">int</span>&gt; vector2;

    <span class="co">/* pseudo-pseudo-random values */</span>
    <span class="kw">for</span> (<span class="dt">int</span> i=<span class="dv">1</span>;i&lt;<span class="dv">4</span>;i++)
        vector1.push_back (i);

    <span class="co">/* alocate memory in vector2 */</span>
    vector2.resize(vector1.size());

    <span class="co">/* applies our lambda function for each element</span>
<span class="co">     * in vector1 and stores it in vector2</span>
<span class="co">     */</span>
    transform (vector1.begin(), vector1.end(), vector2.begin(),
        [] (<span class="dt">int</span> i) { <span class="kw">return</span> ++i; });

    <span class="co">/* output the result */</span>
    cout &lt;&lt; “Vector2 contains: “;
    <span class="kw">for</span> (std::vector&lt;<span class="dt">int</span>&gt;::iterator it=vector2.begin();
        it!=vector2.end(); ++it)
        std::cout &lt;&lt; &#39; &#39; &lt;&lt; *it;

    <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>And the output is:</p>
<pre><code>Vector2 contains: 2 3 4</code></pre>
<p>You can see that our result is the same as in Haskell. We used a lambda function to increment the value for the each element from the first vector and then we printed it to standard output.</p>
</section>
<section id="conclusions" class="level3">
<h3>3. Conclusions</h3>
<p>So, why you should use lambda functions ?</p>
<ul>
<li>You can write fast functions and use them in your production code</li>
<li>You can replace macros (because macros are evil – citation needed)</li>
<li>Because <span class="math">\(\lambda\)</span> rocks</li>
<li>Because you can use it when you want a short-term functionality that you do not want to have to name</li>
</ul>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Tue, 28 Jan 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/lambda-cpp.html</guid>
</item>
<item>
    <title>Inspecting library calls for fun and profit</title>
    <link>http://techblog.rosedu.org/ltrace.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/ltrace.html" title="Inspecting library calls for fun and profit">Inspecting library calls for fun and profit</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on January 18, 2014</span>
      by
      <span class="author"><a href="/people/mihai-maruseac.html">Mihai Maruseac</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/trace.html">trace</a>, <a href="/tags/ltrace.html">ltrace</a>, <a href="/tags/strace.html">strace</a>, <a href="/tags/ptrace.html">ptrace</a>, <a href="/tags/debugging.html">debugging</a></span>
      </span>

      <p>Two years ago this blog had a series of articles on debugging tools. We have presented tools like <a href="http://techblog.rosedu.org/valgrind-introduction.html" title="Valgrind introduction">Valgrind</a> and <a href="http://techblog.rosedu.org/gdb-a-basic-workflow.html" title="GDB - basic workflow">GDB</a> and we stopped with an introduction to <a href="http://techblog.rosedu.org/tracing-processes-for-fun-and-profit.html" title="Tracing Processes for Fun and Profit">strace</a>. At the end of that article we mentioned that there are other tools useful for debugging beyond these three already mentioned. After two years of silence, the debugging series is on with an article on <code>ltrace</code>.</p>
<!--more-->

<p>Ask around developers and you’ll see that the proportion of those knowing about <code>ltrace</code> compared to those knowing how to use <code>strace</code> is at most the same as the proportion of <code>strace</code> users among users knowing how to use <code>gdb</code> and <code>valgrind</code>.</p>
<p>But how is <code>ltrace</code> different? Why is this an useful tool? This article will try to shine some light on this while also providing comparisons with the <code>strace</code> tool.</p>
<section id="basic-example" class="level3">
<h3>Basic Example</h3>
<p>The simples way to use both <code>ltrace</code> and <code>strace</code> is to append this tool in front of the command you’re tracing. We will illustrate here the <a href="http://techblog.rosedu.org/tracing-processes-for-fun-and-profit.html#simple-example" title="Tracing Processes for Fun and Profit">same example used for <code>strace</code></a></p>
<pre><code>$ ltrace ls
__libc_start_main(0x402c60, 1, 0x7fffa36d7038, 0x412bb0 &lt;unfinished ...&gt;
strrchr(&quot;ls&quot;, &#39;/&#39;)                               = nil
setlocale(LC_ALL, &quot;&quot;)                            = &quot;en_US.UTF-8&quot;
bindtextdomain(&quot;coreutils&quot;, &quot;/usr/share/locale&quot;) = &quot;/usr/share/locale&quot;
textdomain(&quot;coreutils&quot;)                          = &quot;coreutils&quot;
__cxa_atexit(0x40ace0, 0, 0, 0x736c6974756572)   = 0
isatty(1)                                        = 1
getenv(&quot;QUOTING_STYLE&quot;)                          = nil
getenv(&quot;COLUMNS&quot;)                                = nil
ioctl(1, 21523, 0x7fffa36d6bd0)                  = 0
getenv(&quot;TABSIZE&quot;)                                = nil
getopt_long(1, 0x7fffa36d7038, &quot;abcdfghiklmnopqrstuvw:xABCDFGHI:&quot;..., 0x61a5e0, -1)         = -1
getenv(&quot;LS_BLOCK_SIZE&quot;)                          = nil
...
opendir(&quot;.&quot;)                                     = 0x2789c30
readdir(0x2789c30)                               = 0x2789c60
readdir(0x2789c30)                               = 0x2789c78
readdir(0x2789c30)                               = 0x2789c90
strlen(&quot;a.out&quot;)                                  = 5
malloc(6)                                        = 0x2791c70
memcpy(0x2791c70, &quot;a.out\0&quot;, 6)                  = 0x2791c70
readdir(0x2789c30)                               = 0x2789cb0
strlen(&quot;out.9373&quot;)                               = 8
malloc(9)                                        = 0x2791c90
memcpy(0x2791c90, &quot;out.9373\0&quot;, 9)               = 0x2791c90
...
closedir(0x2789c30)                              = 0
free(0)                                          = &lt;void&gt;
malloc(432)                                      = 0x2789c30
_setjmp(0x61b640, 0x400000, 0x2785e50, 0x2789cc0)= 0
__errno_location()                               = 0x7f95ad5916c0
strcoll(&quot;out.9307&quot;, &quot;1.c&quot;)                       = 23
...
fwrite_unlocked(&quot;1.c&quot;, 1, 3, 0x3573db9400)       = 3
...
fwrite_unlocked(&quot;out&quot;, 1, 3, 0x3573db9400)       = 3
...
exit(0 &lt;unfinished ...&gt;
__fpending(0x3573db9400, 0, 64, 0x3573db9eb0)    = 0
fileno(0x3573db9400)                             = 1
__freading(0x3573db9400, 0, 64, 0x3573db9eb0)    = 0
__freading(0x3573db9400, 0, 2052, 0x3573db9eb0)  = 0
fflush(0x3573db9400)                             = 0
fclose(0x3573db9400)                             = 0
__fpending(0x3573db91c0, 0, 0x3573dbaa00, 0xfbad000c)= 0
fileno(0x3573db91c0)                             = 2
__freading(0x3573db91c0, 0, 0x3573dbaa00, 0xfbad000c)= 0
__freading(0x3573db91c0, 0, 4, 0xfbad000c)       = 0
fflush(0x3573db91c0)                             = 0
fclose(0x3573db91c0)                             = 0
+++ exited (status 0) +++</code></pre>
<p>Looking at the trace we see that the <code>ls</code> process starts by acknowledging the current <a href="http://en.wikipedia.org/wiki/Locale" title="Locale (computing)">locale</a> after which several environment variables which control the output are read (only a few of them shown, the others ellided by <code>...</code>). Then <a href="http://linuxmanpages.com/man3/opendir.3.php" title="opendir - open a directory"><code>opendir</code></a> is called on <code>.</code> (since <code>ls</code> had no other arguments) and each entry is read via <a href="http://linuxmanpages.com/man2/readdir.2.php" title="readdir - read directory entry"><code>readdir</code></a> and then copied into a vector of entries (after using <code>strdup</code> seen here as a triple of <code>strlen</code>, <code>malloc</code> and <code>memcpy</code>). Next step is to sort all of these entries according to the current locale (<a href="http://linuxmanpages.com/man3/strcoll.3.php" title="strcoll - compare two strings using the current locale"><code>strcoll</code></a>, the variable <code>LC_COLLATE</code>). This allows sorting the filenames in alphabetical order. Then, each filename is written on the <code>1</code> file descriptor (<code>stdout</code>) using the non-blocking <a href="http://linuxmanpages.com/man3/fwrite_unlocked.3.php" title="fwrite_unlocked - non-locking stdio function"><code>fwrite_unlocked</code></a>. Last step is to call <code>exit</code> and flush all open streams.</p>
<p>Right now you are more enlightened on what <code>ls</code> does than before reading this part. Knowing the above information you can do things like changing the way files are quoted (I retrieved the options by providing an invalid value and looking on the <code>QUOTING_STYLE='-' ltrace ls</code> output to see what arguments are tested for):</p>
<pre><code>$ ls a*
a file  a.out

$ QUOTING_STYLE=&quot;shell&quot; ls a*
&#39;a file&#39;  a.out

$ QUOTING_STYLE=&quot;c&quot; ls a*
&quot;a file&quot;  &quot;a.out&quot;</code></pre>
<p>The next question we are interested in is “<em>Can <code>ltrace</code> trace syscalls as well?</em>”. Luckily, the answer is <em>yes</em>, by using the <code>-S</code> flag:</p>
<pre><code>$ ltrace -S ls
SYS_brk(0)                               = 0x1d4b000
SYS_mmap(0, 4096, 3, 34)                 = 0x7f4d8b352000
SYS_access(&quot;/etc/ld.so.preload&quot;, 04)     = -2
SYS_open(&quot;/etc/ld.so.cache&quot;, 524288, 01) = 3
SYS_fstat(3, 0x7fff9f3a4110)             = 0
SYS_mmap(0, 0x246b0, 1, 2)               = 0x7f4d8b32d000
...</code></pre>
<p>Contrast with the results of <code>strace</code>:</p>
<pre><code>$ strace ls
execve(&quot;/usr/bin/ls&quot;, [&quot;ls&quot;], [/* 48 vars */]) = 0
brk(0)                                  = 0x1190000
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fcf80794000
access(&quot;/etc/ld.so.preload&quot;, R_OK)      = -1 ENOENT (No such file or directory)
open(&quot;/etc/ld.so.cache&quot;, O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=149168, ...}) = 0
mmap(NULL, 149168, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fcf8076f000
...</code></pre>
<p>Differences are easily seen. The main one is that <code>ltrace</code> prefixes each syscall with <code>SYS_</code> and doesn’t represent macros as macros but expands them (so instead of <code>PROT_READ|PROT_WRITE</code> you have <code>3</code>). In fact, even the number of arguments is different. For understandability reason, it is better to use <code>strace</code> for tracing the system calls and <code>ltrace</code> for tracing the library ones.</p>
</section>
<section id="why-is-ltrace-useful" class="level3">
<h3>Why Is <code>ltrace</code> Useful?</h3>
<p>From the above section you have seen that we can use <code>ltrace</code> to understand undocumented behavior of an application. For example the <code>QUOTING_STYLE</code> was found neither in the <a href="http://linuxmanpages.com/man1/ls.1.php" title="ls - list directory contents"><code>ls</code></a> manual nor in the <a href="http://linuxmanpages.com/man1/bash.1.php" title="bash - GNU Bourne-Again SHell"><code>bash</code></a> one.</p>
<p>Another way <code>ltrace</code> is useful is when one of the libraries your application depends on is faulty. Instead of trying to debug a full-scale application you might want to isolate the culprit into a minimal application which exhibits only the bad behaviour. For that, you can use <code>ltrace</code> in the same way we used <code>strace</code> in <a href="http://techblog.rosedu.org/tracing-processes-for-fun-and-profit.html#how-is-this-useful" title="Tracing Processes for Fun and Profit">its own article</a> in the past.</p>
</section>
<section id="i-have-too-much-output" class="level3">
<h3>I Have Too Much Output</h3>
<p>Like in the case of <a href="http://techblog.rosedu.org/tracing-processes-for-fun-and-profit.html#too-much-output" title="Tracing Processes for Fun and Profit"><code>strace</code></a>, <code>ltrace</code> produces a long list of output lines and it is quite hard to find what you’re looking for or to understand what’s happening while they are scrolling on the screen.</p>
<p>Just like <code>strace</code> we can save the output to a file, using <code>-o</code>:</p>
<pre><code>$ ltrace -o ltraceout ls
$ wc -l ltraceout
523 ltraceout
$ head ltraceout
__libc_start_main(0x402c60, 1, 0x7fffbc2e3348, 0x412bb0 &lt;unfinished ...&gt;
strrchr(&quot;ls&quot;, &#39;/&#39;)                              = nil
setlocale(LC_ALL, &quot;&quot;)                           = &quot;en_US.UTF-8&quot;
bindtextdomain(&quot;coreutils&quot;, &quot;/usr/share/locale&quot;)= &quot;/usr/share/locale&quot;
textdomain(&quot;coreutils&quot;)                         = &quot;coreutils&quot;
__cxa_atexit(0x40ace0, 0, 0, 0x736c6974756572)  = 0
isatty(1)                                       = 1
getenv(&quot;QUOTING_STYLE&quot;)                         = nil
getenv(&quot;COLUMNS&quot;)                               = nil
ioctl(1, 21523, 0x7fffbc2e2ee0)                 = 0</code></pre>
<p>Like <code>strace</code>, we can also use <code>-e</code> to filter on specific calls.</p>
<p>In the following examples we would use the following C source file which computes <code>41^41</code> and <code>42^42</code> both using the float <code>libmath</code> version and the <code>libgmp</code> multi-precision integers one. We will use threads to compute <code>42^42</code> and compute <code>41^41</code> in the <code>main</code> function with both arguments.</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;math.h&gt;</span>
<span class="ot">#include &lt;pthread.h&gt;</span>
<span class="ot">#include &lt;stdio.h&gt;</span>
<span class="ot">#include &lt;stdlib.h&gt;</span>

<span class="ot">#include &lt;gmp.h&gt;</span>

<span class="dt">void</span> *do_double_thread(<span class="dt">void</span> *data)
{
  <span class="dt">double</span> x = <span class="dv">42</span>;
  x = pow(x, x);
}

<span class="dt">void</span> *do_mpz_thread(<span class="dt">void</span> *data)
{
  mpz_t x;

  mpz_init_set_ui(x, <span class="dv">42</span>);
  mpz_pow_ui(x, x, <span class="dv">42</span>);

  mpz_clear(x);
}

<span class="dt">int</span> main()
{
  pthread_t double_thread, mpz_thread;
  pthread_attr_t attr;

  <span class="dt">double</span> y = <span class="dv">41</span>;
  mpz_t x;

  mpz_init_set_ui(x, <span class="dv">41</span>);
  mpz_pow_ui(x, x, <span class="dv">41</span>);

  mpz_clear(x);

  y = pow(y, y);

  <span class="co">/* initialize the attribute */</span>
  <span class="kw">if</span> (pthread_attr_init(&amp;attr) != <span class="dv">0</span>) {
    perror(<span class="st">&quot;pthread_attr_init&quot;</span>);
    pthread_exit(NULL);
  }

  <span class="co">/* set detached state */</span>
  <span class="kw">if</span> (pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE) != <span class="dv">0</span>) {
    perror(<span class="st">&quot;pthread_attr_setdetachstate&quot;</span>);
    pthread_exit(NULL);
  }

  <span class="kw">if</span> (pthread_create(&amp;double_thread, &amp;attr, do_double_thread, NULL)) {
    perror(<span class="st">&quot;pthread_create&quot;</span>);
    exit(EXIT_FAILURE);
  }

  <span class="kw">if</span> (pthread_create(&amp;mpz_thread, &amp;attr, do_mpz_thread, NULL)) {
    perror(<span class="st">&quot;pthread_create&quot;</span>);
    exit(EXIT_FAILURE);
  }

  pthread_attr_destroy(&amp;attr);

  <span class="kw">if</span> (pthread_join(double_thread, NULL))
    perror(<span class="st">&quot;pthread_join&quot;</span>);

  <span class="kw">if</span> (pthread_join(mpz_thread, NULL))
    perror(<span class="st">&quot;pthread_join&quot;</span>);

  <span class="kw">return</span> <span class="dv">0</span>;
}</code></pre>
<p>To compile, we have to link against <code>libmath</code>, <code>libpthread</code> and <code>libgmp</code>:</p>
<pre><code>$ gcc -lm -lpthread -lgmp test.c -o test</code></pre>
<p>Running <code>ltrace</code> on the full output we have the following:</p>
<pre><code>$ ltrace ./test
__libc_start_main(0x400aeb, 1, 0x7fff6afa8b78, 0x400c60 &lt;unfinished ...&gt;
__gmpz_init_set_ui(0x7fff6afa8a30, 41, 0x7fff6afa8b88, 0x400c60)     = 1
__gmpz_pow_ui(0x7fff6afa8a30, 0x7fff6afa8a30, 41, 0x7fff6afa8a30)    = 0
__gmpz_clear(0x7fff6afa8a30, 0x6bb020, 0, 0x129c08be7ca69)           = 0
pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)                 = 0x4da9465e5d9d1629
pthread_attr_init(0x7fff6afa8a40, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
pthread_attr_setdetachstate(0x7fff6afa8a40, 0, 0x7fefffffffffffff, 0)= 0
pthread_create(0x7fff6afa8a80, 0x7fff6afa8a40, 0x400a60, 0)          = 0
pthread_create(0x7fff6afa8a78, 0x7fff6afa8a40, 0x400aa8, 0)          = 0
pthread_attr_destroy(0x7fff6afa8a40, 0x7f60ece77fb0, 0x7f60ece789d0, -1)= 0
pthread_join(0x7f60ed679700, 0, 0x7f60ece789d0, -1)                  = 0
pthread_join(0x7f60ece78700, 0, 0x7f60ed679700, 0x3574418290)        = 0
+++ exited (status 0) +++</code></pre>
<p>If we want to capture only the bignum operations we can use <code>-e</code> flag:</p>
<pre><code>$ ltrace -e &#39;*gmpz*&#39; ./test
test-&gt;__gmpz_init_set_ui(0x7ffffb01f830, 41, 0x7ffffb01f988, 0x400c60)= 1
test-&gt;__gmpz_pow_ui(0x7ffffb01f830, 0x7ffffb01f830, 41, 0x7ffffb01f830 &lt;unfinished ...&gt;
libgmp.so.10-&gt;__gmpz_n_pow_ui(0x7ffffb01f830, 0xbf0010, 1, 41 &lt;unfinished ...&gt;
libgmp.so.10-&gt;__gmpz_realloc(0x7ffffb01f830, 7, 42, 7)         = 0xbf0010
&lt;... __gmpz_n_pow_ui resumed&gt; )                                  = 0
&lt;... __gmpz_pow_ui resumed&gt; )                                    = 0
test-&gt;__gmpz_clear(0x7ffffb01f830, 0xbf0020, 0, 0x129c08be7ca69) = 0
+++ exited (status 0) +++</code></pre>
<p>From this output we see that <code>__gmpz_pow_ui</code> from our code calls <code>__gmpz_n_pow_ui</code> from <code>libgmp.so.10</code> which in turn calls <code>__gmpz_realloc</code> to expand the space allocated to the number.</p>
<p>However, in some cases one library might call functions from another or you might want to filter and keep only the calls done by your application. Fortunately, we can still do that:</p>
<pre><code>$ ltrace -e &#39;*gmpz*-@libgmp.so*&#39; ./test
test-&gt;__gmpz_init_set_ui(0x7fff45c5cd70, 41, 0x7fff45c5cec8, 0x400c60) = 1
test-&gt;__gmpz_pow_ui(0x7fff45c5cd70, 0x7fff45c5cd70, 41, 0x7fff45c5cd70)= 0
test-&gt;__gmpz_clear(0x7fff45c5cd70, 0xc02020, 0, 0x129c08be7ca69)       = 0
+++ exited (status 0) +++</code></pre>
<p>If you want to trace all calls <em>inside</em> a library then it is better to use <code>-x</code>.</p>
<pre><code>$ ltrace -x &#39;@libgmp.so.*&#39; ./test
__libc_start_main(0x400aeb, 1, 0x7fff656660b8, 0x400c60 &lt;unfinished ...&gt;
__gmpz_init_set_ui(0x7fff65665f70, 41, 0x7fff656660c8, 0x400c60 &lt;unfinished ...&gt;
__gmpz_init_set_ui@libgmp.so.10(0x7fff65665f70, 41, 0x7fff656660c8, 0x400c60 &lt;unfinished ...&gt;
__gmp_default_allocate@libgmp.so.10(8, 41, 0x7fff656660c8, 0x400c60)= 0x222a010
&lt;... __gmpz_init_set_ui resumed&gt; )= 1
&lt;... __gmpz_init_set_ui resumed&gt; )= 1
__gmpz_pow_ui(0x7fff65665f70, 0x7fff65665f70, 41, 0x7fff65665f70 &lt;unfinished ...&gt;
__gmpz_pow_ui@libgmp.so.10(0x7fff65665f70, 0x7fff65665f70, 41, 0x7fff65665f70 &lt;unfinished ...&gt;
__gmpz_n_pow_ui@libgmp.so.10(0x7fff65665f70, 0x222a010, 1, 41 &lt;unfinished ...&gt;
__gmpz_realloc@libgmp.so.10(0x7fff65665f70, 7, 42, 7 &lt;unfinished ...&gt;
__gmp_default_reallocate@libgmp.so.10(0x222a010, 8, 56, 7)= 0x222a010
&lt;... __gmpz_realloc resumed&gt; )= 0x222a010
__gmpn_sqr@libgmp.so.10(0x222a010, 0x7fff65665e80, 2, 48 &lt;unfinished ...&gt;
__gmpn_sqr_basecase@libgmp.so.10(0x222a010, 0x7fff65665e80, 2, 48)= 0x3562f3ea0787ecff
&lt;... __gmpn_sqr resumed&gt; )= 0
__gmpn_mul_1@libgmp.so.10(0x222a010, 0x222a010, 3, 0x129c08be7ca69)= 0xca32f2e
&lt;... __gmpz_n_pow_ui resumed&gt; )= 0
&lt;... __gmpz_pow_ui resumed&gt; )= 0
&lt;... __gmpz_pow_ui resumed&gt; )= 0
__gmpz_clear(0x7fff65665f70, 0x222a020, 0, 0x129c08be7ca69 &lt;unfinished ...&gt;
__gmpz_clear@libgmp.so.10(0x7fff65665f70, 0x222a020, 0, 0x129c08be7ca69 &lt;unfinished ...&gt;
__gmp_default_free@libgmp.so.10(0x222a010, 56, 0, 0x129c08be7ca69)= 0
&lt;... __gmpz_clear resumed&gt; )= 0
&lt;... __gmpz_clear resumed&gt; )= 0
pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)= 0x4da9465e5d9d1629
pthread_attr_init(0x7fff65665f80, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
pthread_attr_setdetachstate(0x7fff65665f80, 0, 0x7fefffffffffffff, 0)= 0
pthread_create(0x7fff65665fc0, 0x7fff65665f80, 0x400a60, 0)= 0
pthread_create(0x7fff65665fb8, 0x7fff65665f80, 0x400aa8, 0)= 0
pthread_attr_destroy(0x7fff65665f80, 0x7f3164bc1fb0, 0x7f3164bc29d0, -1)= 0
pthread_join(0x7f31653c3700, 0, 0x7f3164bc29d0, -1)= 0
pthread_join(0x7f3164bc2700, 0, 0x7f31653c3700, 0x3574418290)= 0
_fini@libgmp.so.10(0x358cc761f0, 0, 0xffffffff, 0)= 0x358ca5edc4
+++ exited (status 0) +++</code></pre>
<p>To catch only the calls to the specific library use <code>-L</code> which will make <code>ltrace</code> not trace anything from the <code>MAIN</code> library:</p>
<pre><code>$ ltrace -L -x &#39;@libgmp.so.*&#39; ./test
__gmpz_init_set_ui@libgmp.so.10(0x7fffbf630930, 41, 0x7fffbf630a88, 0x400c60 &lt;unfinished ...&gt;
__gmp_default_allocate@libgmp.so.10(8, 41, 0x7fffbf630a88, 0x400c60)= 0x17b5010
&lt;... __gmpz_init_set_ui resumed&gt; )= 1
__gmpz_pow_ui@libgmp.so.10(0x7fffbf630930, 0x7fffbf630930, 41, 0x7fffbf630930 &lt;unfinished ...&gt;
__gmpz_n_pow_ui@libgmp.so.10(0x7fffbf630930, 0x17b5010, 1, 41 &lt;unfinished ...&gt;
__gmpz_realloc@libgmp.so.10(0x7fffbf630930, 7, 42, 7 &lt;unfinished ...&gt;
__gmp_default_reallocate@libgmp.so.10(0x17b5010, 8, 56, 7)= 0x17b5010
&lt;... __gmpz_realloc resumed&gt; )= 0x17b5010
__gmpn_sqr@libgmp.so.10(0x17b5010, 0x7fffbf630840, 2, 48 &lt;unfinished ...&gt;
__gmpn_sqr_basecase@libgmp.so.10(0x17b5010, 0x7fffbf630840, 2, 48)= 0x3562f3ea0787ecff
&lt;... __gmpn_sqr resumed&gt; )= 0
__gmpn_mul_1@libgmp.so.10(0x17b5010, 0x17b5010, 3, 0x129c08be7ca69)= 0xca32f2e
&lt;... __gmpz_n_pow_ui resumed&gt; )= 0
&lt;... __gmpz_pow_ui resumed&gt; )= 0
__gmpz_clear@libgmp.so.10(0x7fffbf630930, 0x17b5020, 0, 0x129c08be7ca69 &lt;unfinished ...&gt;
__gmp_default_free@libgmp.so.10(0x17b5010, 56, 0, 0x129c08be7ca69)= 0
&lt;... __gmpz_clear resumed&gt; )= 0
_fini@libgmp.so.10(0x358cc761f0, 0, 0xffffffff, 0)= 0x358ca5edc4
+++ exited (status 0) +++</code></pre>
</section>
<section id="attaching-to-other-processes" class="level3">
<h3>Attaching To Other Processes</h3>
<p>Like in <a href="http://techblog.rosedu.org/tracing-processes-for-fun-and-profit.html#but-i-started-the-process.." title="Tracing Processes for Fun and Profit"><code>strace</code></a> case, we can use <code>-p</code> to attach to running processes:</p>
<pre><code>$ ./test &amp;
[1] 26026

$ ltrace -p 26026
__gmpz_clear(0x7fff1fa3bb50, 1, 0, 0x1b9b000)= 0
pow(0x7f2c3dca8000, 0x49ff000, 0x4044800000000000, -1)= 0x4da9465e5d9d1629
pthread_attr_init(0x7fff1fa3bb60, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
pthread_attr_setdetachstate(0x7fff1fa3bb60, 0, 0x7fefffffffffffff, 0)= 0
pthread_create(0x7fff1fa3bba8, 0x7fff1fa3bb60, 0x400a60, 0)= 0
pthread_create(0x7fff1fa3bba0, 0x7fff1fa3bb60, 0x400aa8, 0)= 0
pthread_attr_destroy(0x7fff1fa3bb60, 0x7f2c42073fb0, 0x7f2c420749d0, -1)= 0
pthread_join(0x7f2c42875700, 0, 0x7f2c420749d0, -1)= 0
pthread_join(0x7f2c42074700, 0, 0x7f2c42875700, 0x3574418290)= 0
+++ exited (status 0) +++
[1]+  Done                    ./test</code></pre>
<p>In fact, just as <code>strace</code>, we can use multiple <code>-p</code> arguments to attach to multiple processes simultaneously:</p>
<pre><code>$ ./test &amp; ./test &amp;
[1] 26149
[2] 26150

$ ltrace -p 26149 -p 26150
__gmpz_clear(0x7fff52a4fed0, 1, 0, 0xa2c000)= 0
pow(0x7f85fb6f0000, 0x49ff000, 0x4044800000000000, -1)= 0x4da9465e5d9d1629
pthread_attr_init(0x7fff52a4fee0, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
pthread_attr_setdetachstate(0x7fff52a4fee0, 0, 0x7fefffffffffffff, 0)= 0
pthread_create(0x7fff52a4ff28, 0x7fff52a4fee0, 0x400a60, 0)= 0
pthread_create(0x7fff52a4ff20, 0x7fff52a4fee0, 0x400aa8, 0)= 0
pthread_attr_destroy(0x7fff52a4fee0, 0x7f85ffabbfb0, 0x7f85ffabc9d0, -1)= 0
pthread_join(0x7f86002bd700, 0, 0x7f85ffabc9d0, -1)= 0
pthread_join(0x7f85ffabc700, 0, 0x7f86002bd700, 0x3574418290)= 0
+++ exited (status 0) +++
__gmpz_clear(0x7fff4cbac6e0, 1, 0, 0x1207000)= 0
pow(0x7fbf03640000, 0x49ff000, 0x4044800000000000, -1)= 0x4da9465e5d9d1629
pthread_attr_init(0x7fff4cbac6f0, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
pthread_attr_setdetachstate(0x7fff4cbac6f0, 0, 0x7fefffffffffffff, 0)= 0
pthread_create(0x7fff4cbac738, 0x7fff4cbac6f0, 0x400a60, 0)= 0
pthread_create(0x7fff4cbac730, 0x7fff4cbac6f0, 0x400aa8, 0)= 0
pthread_attr_destroy(0x7fff4cbac6f0, 0x7fbf07a0bfb0, 0x7fbf07a0c9d0, -1)= 0
pthread_join(0x7fbf0820d700, 0, 0x7fbf07a0c9d0, -1)= 0
pthread_join(0x7fbf07a0c700, 0, 0x7fbf0820d700, 0x3574418290)= 0
+++ exited (status 0) +++
[1]-  Done                    ./test
[2]+  Done                    ./test</code></pre>
<p>Though, this case is useful only when debugging multiple programs which need to communicate between themselves, it is nice to know that this is possible.</p>
</section>
<section id="tracing-the-threads-and-children-of-a-process" class="level3">
<h3>Tracing the Threads and Children of a Process</h3>
<p>The <code>strace</code> tools allows attaching to subprocesses of a process using <code>-f</code>. Also, you can use <code>-ff</code> with a <code>-o</code> to get the output of each thread in a separate file.</p>
<p>However, <code>ltrace</code> knows only the <code>-f</code> option. Lines from different processes are prefixed with the <code>PID</code> of that process.</p>
<pre><code>$ ltrace -f ./test
[pid 26192] __libc_start_main(0x400aeb, 1, 0x7fffc406b9c8, 0x400c60 &lt;unfinished ...&gt;
[pid 26192] __gmpz_init_set_ui(0x7fffc406b880, 41, 0x7fffc406b9d8, 0x400c60)= 1
[pid 26192] __gmpz_pow_ui(0x7fffc406b880, 0x7fffc406b880, 41, 0x7fffc406b880)= 0
[pid 26192] __gmpz_clear(0x7fffc406b880, 0x1b21020, 0, 0x129c08be7ca69)= 0
[pid 26192] pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)= 0x4da9465e5d9d1629
[pid 26192] pthread_attr_init(0x7fffc406b890, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
[pid 26192] pthread_attr_setdetachstate(0x7fffc406b890, 0, 0x7fefffffffffffff, 0)           = 0
[pid 26192] pthread_create(0x7fffc406b8d0, 0x7fffc406b890, 0x400a60, 0)= 0
[pid 26193] pow(0, 0, 0x4045000000000000, -1 &lt;unfinished ...&gt;
[pid 26192] pthread_create(0x7fffc406b8c8, 0x7fffc406b890, 0x400aa8, 0 &lt;unfinished ...&gt;
[pid 26193] &lt;... pow resumed&gt; )= 0x4e1646505f35a847
[pid 26193] +++ exited (status 0) +++
[pid 26192] &lt;... pthread_create resumed&gt; )= 0
[pid 26192] pthread_attr_destroy(0x7fffc406b890, 0x7fc1a1041fb0, 0x7fc1a10429d0, -1)= 0
[pid 26192] pthread_join(0x7fc1a1843700, 0, 0x7fc1a10429d0, -1)= 0
[pid 26192] pthread_join(0x7fc1a1042700, 0, 0x7fc1a1843700, 0x3574418290 &lt;unfinished ...&gt;
[pid 26194] __gmpz_init_set_ui(0x7fc1a1041f00, 42, 0x59a85877c49edc2b, -1)= 1
[pid 26194] __gmpz_pow_ui(0x7fc1a1041f00, 0x7fc1a1041f00, 42, 0x7fc1a1041f00)= 0
[pid 26194] __gmpz_clear(0x7fc1a1041f00, 0x7fc19c0008c0, 0, 42)= 0
[pid 26192] &lt;... pthread_join resumed&gt; )= 0
[pid 26194] +++ exited (status 0) +++
[pid 26192] +++ exited (status 0) +++</code></pre>
<p>Thus, if you want to filter only a single child you have to resort to text filter utilities like <code>grep</code>.</p>
</section>
<section id="profiling" class="level3">
<h3>Profiling</h3>
<p>One nice thing about <code>strace</code> is that you can use the <code>-c</code> flag to get a table with all syscalls used in a program, the time needed to execute them and the count of error results. However, <code>ltrace</code> lacks this option but it can be simulated by using the other timing options and text filters.</p>
<p>Both <code>strace</code> and <code>ltrace</code> allow you to get timestamps around any call by using <code>-r</code>, <code>-t</code>, <code>-tt</code> or <code>-ttt</code>:</p>
<p><code>-r</code> shows a relative timestamp since program startup</p>
<pre><code>$ ltrace -r ./test
  0.000000 __libc_start_main(0x400aeb, 1, 0x7fff2a51a328, 0x400c60 &lt;unfinished ...&gt;
  0.000418 __gmpz_init_set_ui(0x7fff2a51a1e0, 41, 0x7fff2a51a338, 0x400c60)= 1
  0.000296 __gmpz_pow_ui(0x7fff2a51a1e0, 0x7fff2a51a1e0, 41, 0x7fff2a51a1e0)= 0
  0.000166 __gmpz_clear(0x7fff2a51a1e0, 0x1f66020, 0, 0x129c08be7ca69)= 0
  0.000137 pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)= 0x4da9465e5d9d1629
  0.000168 pthread_attr_init(0x7fff2a51a1f0, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
  0.000147 pthread_attr_setdetachstate(0x7fff2a51a1f0, 0, 0x7fefffffffffffff, 0)= 0
  0.000216 pthread_create(0x7fff2a51a230, 0x7fff2a51a1f0, 0x400a60, 0)= 0
  0.000409 pthread_create(0x7fff2a51a228, 0x7fff2a51a1f0, 0x400aa8, 0)= 0
  0.000474 pthread_attr_destroy(0x7fff2a51a1f0, 0x7f25016c5fb0, 0x7f25016c69d0, -1)= 0
  0.000250 pthread_join(0x7f2501ec7700, 0, 0x7f25016c69d0, -1)= 0
  0.000257 pthread_join(0x7f25016c6700, 0, 0x7f2501ec7700, 0x3574418290)= 0
  0.000735 +++ exited (status 0) +++</code></pre>
<p><code>-t</code> shows the time of day when the call was made</p>
<pre><code>$ ltrace -t ./test
14:50:42 __libc_start_main(0x400aeb, 1, 0x7fff84229b38, 0x400c60 &lt;unfinished ...&gt;
14:50:42 __gmpz_init_set_ui(0x7fff842299f0, 41, 0x7fff84229b48, 0x400c60)= 1
14:50:42 __gmpz_pow_ui(0x7fff842299f0, 0x7fff842299f0, 41, 0x7fff842299f0)= 0
14:50:42 __gmpz_clear(0x7fff842299f0, 0x1d02020, 0, 0x129c08be7ca69)= 0
14:50:42 pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)= 0x4da9465e5d9d1629
14:50:42 pthread_attr_init(0x7fff84229a00, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
14:50:42 pthread_attr_setdetachstate(0x7fff84229a00, 0, 0x7fefffffffffffff, 0)= 0
14:50:42 pthread_create(0x7fff84229a40, 0x7fff84229a00, 0x400a60, 0)= 0
14:50:42 pthread_create(0x7fff84229a38, 0x7fff84229a00, 0x400aa8, 0)= 0
14:50:42 pthread_attr_destroy(0x7fff84229a00, 0x7f48e7ec0fb0, 0x7f48e7ec19d0, -1)= 0
14:50:42 pthread_join(0x7f48e86c2700, 0, 0x7f48e7ec19d0, -1)= 0
14:50:42 pthread_join(0x7f48e7ec1700, 0, 0x7f48e86c2700, 0x3574418290)= 0
14:50:42 +++ exited (status 0) +++</code></pre>
<p><code>-tt</code> also displays the microseconds</p>
<pre><code>$ ltrace -tt ./test
14:50:45.465708 __libc_start_main(0x400aeb, 1, 0x7fff83373968, 0x400c60 &lt;unfinished ...&gt;
14:50:45.465942 __gmpz_init_set_ui(0x7fff83373820, 41, 0x7fff83373978, 0x400c60)= 1
14:50:45.466216 __gmpz_pow_ui(0x7fff83373820, 0x7fff83373820, 41, 0x7fff83373820)= 0
14:50:45.466400 __gmpz_clear(0x7fff83373820, 0x192e020, 0, 0x129c08be7ca69)= 0
14:50:45.466584 pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)= 0x4da9465e5d9d1629
14:50:45.466764 pthread_attr_init(0x7fff83373830, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
14:50:45.466932 pthread_attr_setdetachstate(0x7fff83373830, 0, 0x7fefffffffffffff, 0)= 0
14:50:45.467101 pthread_create(0x7fff83373870, 0x7fff83373830, 0x400a60, 0)= 0
14:50:45.467417 pthread_create(0x7fff83373868, 0x7fff83373830, 0x400aa8, 0)= 0
14:50:45.468024 pthread_attr_destroy(0x7fff83373830, 0x7fc1e7ebdfb0, 0x7fc1e7ebe9d0, -1)= 0
14:50:45.468253 pthread_join(0x7fc1e86bf700, 0, 0x7fc1e7ebe9d0, -1)= 0
14:50:45.468480 pthread_join(0x7fc1e7ebe700, 0, 0x7fc1e86bf700, 0x3574418290)= 0
14:50:45.469108 +++ exited (status 0) +++</code></pre>
<p><code>-ttt</code> displays microseconds as above but use the seconds till epoch instead of the actual time.</p>
<pre><code>$ ltrace -ttt ./test
1390074648.833755 __libc_start_main(0x400aeb, 1, 0x7fff5b1c8e28, 0x400c60 &lt;unfinished ...&gt;
1390074648.833981 __gmpz_init_set_ui(0x7fff5b1c8ce0, 41, 0x7fff5b1c8e38, 0x400c60)= 1
1390074648.834289 __gmpz_pow_ui(0x7fff5b1c8ce0, 0x7fff5b1c8ce0, 41, 0x7fff5b1c8ce0)= 0
1390074648.834481 __gmpz_clear(0x7fff5b1c8ce0, 0x1e7c020, 0, 0x129c08be7ca69)= 0
1390074648.834678 pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)= 0x4da9465e5d9d1629
1390074648.834858 pthread_attr_init(0x7fff5b1c8cf0, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0
1390074648.835033 pthread_attr_setdetachstate(0x7fff5b1c8cf0, 0, 0x7fefffffffffffff, 0)= 0
1390074648.835242 pthread_create(0x7fff5b1c8d30, 0x7fff5b1c8cf0, 0x400a60, 0)= 0
1390074648.835935 pthread_create(0x7fff5b1c8d28, 0x7fff5b1c8cf0, 0x400aa8, 0)= 0
1390074648.836327 pthread_attr_destroy(0x7fff5b1c8cf0, 0x7fc3da214fb0, 0x7fc3da2159d0, -1)= 0
1390074648.837980 pthread_join(0x7fc3daa16700, 0, 0x7fc3da2159d0, -1)= 0
1390074648.838436 pthread_join(0x7fc3da215700, 0, 0x7fc3daa16700, 0x3574418290)= 0
1390074648.839230 +++ exited (status 0) +++</code></pre>
<p>Also, both tools allow you to time each individual call by using <code>-T</code>:</p>
<pre><code>$ ltrace -T ./test
__libc_start_main(0x400aeb, 1, 0x7fffc4512768, 0x400c60 &lt;unfinished ...&gt;
__gmpz_init_set_ui(0x7fffc4512620, 41, 0x7fffc4512778, 0x400c60)    = 1 &lt;0.000290&gt;
__gmpz_pow_ui(0x7fffc4512620, 0x7fffc4512620, 41, 0x7fffc4512620)   = 0 &lt;0.000167&gt;
__gmpz_clear(0x7fffc4512620, 0x21cc020, 0, 0x129c08be7ca69)         = 0 &lt;0.000142&gt;
pow(0x3573db8760, 0xffffffff, 0x4044800000000000, 0)                = 0x4da9465e5d9d1629 &lt;0.000209&gt;
pthread_attr_init(0x7fffc4512630, 213, 0x7fefffffffffffff, 0x7fffffffffffffff)= 0 &lt;0.000130&gt;
pthread_attr_setdetachstate(0x7fffc4512630, 0, 0x7fefffffffffffff, 0)= 0 &lt;0.000139&gt;
pthread_create(0x7fffc4512670, 0x7fffc4512630, 0x400a60, 0)         = 0 &lt;0.000304&gt;
pthread_create(0x7fffc4512668, 0x7fffc4512630, 0x400aa8, 0)         = 0 &lt;0.000421&gt;
pthread_attr_destroy(0x7fffc4512630, 0x7f09988a1fb0, 0x7f09988a29d0, -1)= 0 &lt;0.000266&gt;
pthread_join(0x7f09990a3700, 0, 0x7f09988a29d0, -1)                 = 0 &lt;0.000181&gt;
pthread_join(0x7f09988a2700, 0, 0x7f09990a3700, 0x3574418290)       = 0 &lt;0.000467&gt;
+++ exited (status 0) +++</code></pre>
<p>Though you can profile applications using <code>ltrace</code> and <code>strace</code>, a much better tool to use is <code>perf</code> which will be presented on a future article.</p>
</section>
<section id="blaming-it-on-the-culprit-line" class="level3">
<h3>Blaming it on the Culprit Line</h3>
<p>It is possible to use <code>ltrace</code> and <code>strace</code> to show you the line numbers of the caller by using the <code>-i</code> flag to get the value of the <code>EIP</code> register and then using <a href="http://linuxmanpages.com/man1/addr2line.1.php" title="addr2line - convert addresses into file names and line numbers"><code>addr2line</code></a> to get the exact line (compile with <code>-g</code>):</p>
<pre><code>$ ltrace -i ./test
...
[0x400bfb] pthread_create(0x7fff0804c998, 0x7fff0804c960, 0x400aa8, 0)= 0
[0x400c1f] pthread_attr_destroy(0x7fff0804c960, 0x7f708d112fb0, 0x7f708d1139d0, -1)= 0
...
[0xffffffffffffffff] +++ exited (status 0) +++

$ addr2line -iCse ./test 0x400c1f
test.c:63</code></pre>
<p>This is useful when your code makes repeated calls to the same subset of functions but only a few of them cause problems.</p>
</section>
<section id="nicer-output" class="level3">
<h3>Nicer Output</h3>
<p>One interesting feature of <code>ltrace</code> is that you can get a nice call tree when functions from one library call other traced functions. For that, you would use the <code>-n</code> option.</p>
<pre><code>$ ltrace -n 3 -L -x &#39;@libgmp.so.*&#39; ./test
__gmpz_init_set_ui@libgmp.so.10(0x7fff7bb2e810, 41, 0x7fff7bb2e968, 0x400c60 &lt;unfinished ...&gt;
   __gmp_default_allocate@libgmp.so.10(8, 41, 0x7fff7bb2e968, 0x400c60)= 0x12b2010
&lt;... __gmpz_init_set_ui resumed&gt; )= 1
__gmpz_pow_ui@libgmp.so.10(0x7fff7bb2e810, 0x7fff7bb2e810, 41, 0x7fff7bb2e810 &lt;unfinished ...&gt;
   __gmpz_n_pow_ui@libgmp.so.10(0x7fff7bb2e810, 0x12b2010, 1, 41 &lt;unfinished ...&gt;
      __gmpz_realloc@libgmp.so.10(0x7fff7bb2e810, 7, 42, 7 &lt;unfinished ...&gt;
         __gmp_default_reallocate@libgmp.so.10(0x12b2010, 8, 56, 7)= 0x12b2010
      &lt;... __gmpz_realloc resumed&gt; )= 0x12b2010
      __gmpn_sqr@libgmp.so.10(0x12b2010, 0x7fff7bb2e720, 2, 48 &lt;unfinished ...&gt;
         __gmpn_sqr_basecase@libgmp.so.10(0x12b2010, 0x7fff7bb2e720, 2, 48)= 0x3562f3ea0787ecff
      &lt;... __gmpn_sqr resumed&gt; )= 0
      __gmpn_mul_1@libgmp.so.10(0x12b2010, 0x12b2010, 3, 0x129c08be7ca69)= 0xca32f2e
   &lt;... __gmpz_n_pow_ui resumed&gt; )= 0
&lt;... __gmpz_pow_ui resumed&gt; )= 0
__gmpz_clear@libgmp.so.10(0x7fff7bb2e810, 0x12b2020, 0, 0x129c08be7ca69 &lt;unfinished ...&gt;
   __gmp_default_free@libgmp.so.10(0x12b2010, 56, 0, 0x129c08be7ca69)= 0
&lt;... __gmpz_clear resumed&gt; )= 0
_fini@libgmp.so.10(0x358cc761f0, 0, 0xffffffff, 0)= 0x358ca5edc4
+++ exited (status 0) +++</code></pre>
<p>If <code>ltrace</code> was compiled with <code>libunwind</code> support then you can also use the <code>-w</code> option to get a backtrace for a specific number of frames around each traced call. If not (like in our case) one can still use the <code>-i</code> way or the <code>-n</code>, depending on what he is interested in.</p>
</section>
<section id="conclusions" class="level3">
<h3>Conclusions</h3>
<p>Though very rarely used, <code>ltrace</code> is a nice program to have in your toolbox. It will greatly help you in those hard to debug cases caused by undocumented behaviors of third-party libraries.</p>
<p>Notice that <code>ltrace</code> has most of the bugs of <code>strace</code>:</p>
<ol type="1">
<li>a program with <code>setuid</code> doesn’t have <code>euid</code> privileges while being traced</li>
<li>a program is slow while being traced</li>
<li>the <code>-i</code> support is weak</li>
</ol>
<p>Next article on this series will present tools for profiling applications and solving timing bugs.</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Sat, 18 Jan 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/ltrace.html</guid>
</item>
<item>
    <title>A superficial exploration of Haskell - part 1</title>
    <link>http://techblog.rosedu.org/haskell-part1.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/haskell-part1.html" title="A superficial exploration of Haskell - part 1">A superficial exploration of Haskell - part 1</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on January  7, 2014</span>
      by
      <span class="author"><a href="/people/dan-serban.html">Dan Șerban</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/haskell.html">haskell</a></span>
      </span>

      <p>This series of blog posts is aimed at experienced programmers who have heard that Haskell is an interesting programming language, but have not had the chance to invest any time in researching it.</p>
<p>In this series I am going to highlight a few remarkable things at a high level, while glossing over some implementation details that would take too long to explain properly. Therefore, expect a lot of “here’s a practical application of Haskell and here’s some sample code, but don’t ask to see the gory details” hand-waving.</p>
<p>For the purposes of this series, I will simply assume that it’s easy for the experienced reader to jump into a new imperative programming language after a few hours or days of becoming familiar with its syntax. And I’ll start with an example that illustrates how you have to adopt a completely different mindset when you start learning Haskell.</p>
<p>Part 1 of this series covers:</p>
<ul>
<li>Mutability</li>
<li>Upside Down Maps</li>
<li>Tokenizing Kernel Code</li>
</ul>
<!--more-->

<p><strong>Before you ask:</strong> All the Haskell snippets I’m showing here consist of GHCi interactive console sessions. I have configured a custom prompt for myself, by placing the line <code>:set prompt &quot;λ: &quot;</code> in GHCi’s configuration file <code>~/.ghc/ghci.conf</code>. The prompt is going to <a href="http://www.haskell.org/ghc/docs/7.6.2/html/users_guide/interactive-evaluation.html">look different</a> if you’re just starting out with a freshly installed copy of Haskell.</p>
<section id="mutability" class="level3">
<h3>Mutability</h3>
<p>To start with, here’s a Python code sample, cut and pasted from a Python 2.7 REPL (interactive console session):</p>
<pre class="sourceCode python"><code class="sourceCode python">&gt;&gt;&gt; x = <span class="dv">1</span>
&gt;&gt;&gt; x = x + <span class="dv">1</span>
&gt;&gt;&gt; x
<span class="dv">2</span>
&gt;&gt;&gt;</code></pre>
<p>Nothing could be simpler!</p>
<p>OK then. Time to port this snippet of code over to Haskell. I’m just going to go with the flow and naively assume – just as many newcomers to Haskell would – that porting Python code is a direct 1-to-1 syntactic translation, in other words, an easy, straightforward thing to do.</p>
<p>The following is what happens in the Haskell REPL (called GHCi). By the way, here we have to prepend the keyword <code>let</code> - it’s the law of the land in GHCi:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="kw">let</span> x <span class="fu">=</span> <span class="dv">1</span>
λ: <span class="kw">let</span> x <span class="fu">=</span> x <span class="fu">+</span> <span class="dv">1</span>
λ: x
<span class="fu">^</span><span class="dt">CInterrupted</span><span class="fu">.</span>
λ:</code></pre>
<p>Huh? What just happened? I was expecting Haskell to compute the value 2. It took forever for the GHCi interactive console to evaluate <code>x</code>, so I got bored and pressed <code>Ctrl-C</code>. What’s happening? Explain this to me.</p>
<p>Well, as one Reddit commenter once observed, this is just one of the many things Haskell does to haze you during your initiation.</p>
<p>What you’re actually doing is giving Haskell a puzzle (<code>x = x + 1</code>) and saying “Go find me a solution”. Mathematically speaking, there are only 2 possible solutions to that puzzle: <span class="math">\(\infty\)</span> and <span class="math">\(- \infty\)</span>. So when you saw it hang, Haskell wasn’t merely taking its time – for no good reason – before giving you back the value 2. Instead, Haskell’s runtime was trying its hardest to give you a correct result by taking every integer value it could think of, one by one, and checking whether it was equal to its successor.</p>
<p>Just to be clear, there is a way to emulate the behavior of the Python snippet we saw above, and the Haskell code for doing that looks like this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="kw">let</span> x <span class="fu">=</span> <span class="dv">1</span>
λ: x <span class="ot">&lt;-</span> return <span class="fu">$</span> x <span class="fu">+</span> <span class="dv">1</span>
λ: x
<span class="dv">2</span>
λ:</code></pre>
<p>As you can see, the syntax is much more verbose (and uglier) than in Python, and for good reason – in Haskell, you are strongly discouraged from using variables and mutation as the primary means of expressing algorithms.</p>
<p>Haskell is divided in two major parts: a crystal palace of unspeakable beauty and <em>mathematical purity</em>, and an imperative ghetto for doing <em>I/O</em> and dealing with <em>mutation</em>. The equal sign in <code>x = x + 1</code> lives in the beautiful palace and symbolizes mathematical unification, while the construct <code>&lt;- return $</code> lives in the ghetto and means “evaluate the right hand side and shove the result into the identifier on the left hand side, thus overwriting what was there beforehand, in true imperative style”.</p>
</section>
<section id="reverse-map-upside-down-map-you-decide" class="level3">
<h3>Reverse Map? Upside Down Map? You decide</h3>
<p>OK, for the next segment I’m going to assume that your beloved programming language of choice has a construct called <code>map</code>, and that you know how to use it.</p>
<p>We start again with some Python code. While Python does indeed offer a higher-order function called <code>map</code>, it’s much more common for experienced Python developers to prefer using a list comprehension, like this:</p>
<pre class="sourceCode Python"><code class="sourceCode python">&gt;&gt;&gt; <span class="dt">list</span> = <span class="dt">range</span>(<span class="dv">20</span>,<span class="dv">31</span>)
&gt;&gt;&gt; <span class="dt">list</span>
[<span class="dv">20</span>, <span class="dv">21</span>, <span class="dv">22</span>, <span class="dv">23</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">26</span>, <span class="dv">27</span>, <span class="dv">28</span>, <span class="dv">29</span>, <span class="dv">30</span>]
&gt;&gt;&gt; [ x + <span class="dv">1</span> <span class="kw">for</span> x in <span class="dt">list</span> ]
[<span class="dv">21</span>, <span class="dv">22</span>, <span class="dv">23</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">26</span>, <span class="dv">27</span>, <span class="dv">28</span>, <span class="dv">29</span>, <span class="dv">30</span>, <span class="dv">31</span>]
&gt;&gt;&gt;</code></pre>
<p>Nothing new or earth-shattering - I would hope - so here’s the Haskell equivalent before we jump into the interesting stuff:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="kw">let</span> list <span class="fu">=</span> [<span class="dv">20</span><span class="fu">..</span><span class="dv">30</span>]
λ: list
[<span class="dv">20</span>,<span class="dv">21</span>,<span class="dv">22</span>,<span class="dv">23</span>,<span class="dv">24</span>,<span class="dv">25</span>,<span class="dv">26</span>,<span class="dv">27</span>,<span class="dv">28</span>,<span class="dv">29</span>,<span class="dv">30</span>]
λ: map (<span class="fu">+</span><span class="dv">1</span>) list
[<span class="dv">21</span>,<span class="dv">22</span>,<span class="dv">23</span>,<span class="dv">24</span>,<span class="dv">25</span>,<span class="dv">26</span>,<span class="dv">27</span>,<span class="dv">28</span>,<span class="dv">29</span>,<span class="dv">30</span>,<span class="dv">31</span>]
λ:</code></pre>
<p>So the basic idea I’m getting at here is that in the beginning we have:</p>
<ul>
<li>one single operation (compute an integer’s successor)</li>
<li>a list of integer values</li>
</ul>
<p><strong>Now for the interesting part.</strong></p>
<p>Let’s take those bullet points above and turn them upside down, such that in the beginning we have:</p>
<ul>
<li>one single integer value</li>
<li>a list of unary integer-to-integer operations</li>
</ul>
<p>Python can still deal with this situation fairly well, since Python’s functions are first-class values (you can place several of them inside of a list). But the Python code wouldn’t be as concise or expressive as the Haskell equivalent, shown here:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="kw">let</span> function_list_1 <span class="fu">=</span> [(<span class="fu">+</span><span class="dv">2</span>),(<span class="fu">*</span><span class="dv">3</span>),(<span class="fu">^</span><span class="dv">2</span>)]
λ: <span class="kw">let</span> function_list_2 <span class="fu">=</span> [(<span class="fu">*</span><span class="dv">5</span>),(<span class="fu">+</span><span class="dv">7</span>),(<span class="fu">*</span><span class="dv">4</span>),(subtract <span class="dv">10</span>)]
λ: <span class="kw">let</span> i <span class="fu">=</span> <span class="dv">12</span>
λ: <span class="kw">import </span><span class="dt">Control.Applicative</span>
λ: function_list_1 <span class="fu">&lt;*&gt;</span> [i]
[<span class="dv">14</span>,<span class="dv">36</span>,<span class="dv">144</span>]
λ: function_list_2 <span class="fu">&lt;*&gt;</span> [i]
[<span class="dv">60</span>,<span class="dv">19</span>,<span class="dv">48</span>,<span class="dv">2</span>]
λ:</code></pre>
<p><strong>Side note:</strong> Due to brevity concerns, it is not practical to go into a detailed explanation of the <code>&lt;*&gt;</code> operator in <code>Control.Applicative</code> (a module in Haskell’s standard library). That is a topic for another blog post. The point here was to show how concisely you can express non-trivial computations with Haskell.</p>
<p><strong>Fun fact:</strong> implementing the “upside-down map” described above was recently a requirement for admittance into <a href="http://webdev.rosedu.org/">WebDev</a> (an extracurricular course organized by ROSEdu). Candidates sent us solutions they had written in various programming languages, with varying degrees of conciseness. We found that the most verbose implementations were predominantly Java-based.</p>
</section>
<section id="lets-tokenize-some-kernel-code" class="level3">
<h3>Let’s tokenize some kernel code</h3>
<p>For the next segment I’ll just grab a <a href="https://github.com/torvalds/linux/blob/master/kernel/sched/fair.c#L507">snippet of code from the Linux kernel</a> and demonstrate how concisely you can express a tokenizer for it in Haskell.</p>
<p>The code for Linux’s completely fair scheduler is stored in a file called <code>fair.c</code>; I’ll just grab a small function from it (function <code>__enqueue_entity</code>, which starts at line 507) and store it locally in a file called <code>enqueue_entity.c</code>.</p>
<p>Here’s what I do subsequently, step by step:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: sample_cfs_code <span class="ot">&lt;-</span> readFile <span class="st">&quot;enqueue_entity.c&quot;</span>
λ:</code></pre>
<p>I just slurped the contents of the file into <code>sample_cfs_code</code>. This is our raw material, let’s look at it:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: sample_cfs_code
<span class="st">&quot;static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n        struct rb_node **link = &amp;cfs_rq-&gt;tasks_timeline.rb_node;\n        struct rb_node *parent = NULL;\n        struct sched_entity *entry;\n        int leftmost = 1;\n        while (*link) {\n                parent = *link;\n                entry = rb_entry(parent, struct sched_entity, run_node);\n                if (entity_before(se, entry)) {\n                        link = &amp;parent-&gt;rb_left;\n                } else {\n                        link = &amp;parent-&gt;rb_right;\n                        leftmost = 0;\n                }\n        }\n        if (leftmost)\n                cfs_rq-&gt;rb_leftmost = &amp;se-&gt;run_node;\n\n        rb_link_node(&amp;se-&gt;run_node, parent, link);\n        rb_insert_color(&amp;se-&gt;run_node, &amp;cfs_rq-&gt;tasks_timeline);\n}\n\n&quot;</span>
λ:</code></pre>
<p>We now define our tokenizing function in Haskell (I trust you will appreciate how concise it is):</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="kw">import </span><span class="dt">Data.List</span>
λ: <span class="kw">let</span> tokenize_this <span class="fu">=</span> unfoldr (\x <span class="ot">-&gt;</span> <span class="kw">case</span> lex x <span class="kw">of</span> [(<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>)] <span class="ot">-&gt;</span> <span class="dt">Nothing</span>; x<span class="fu">:</span>_ <span class="ot">-&gt;</span> <span class="dt">Just</span> x)
λ:</code></pre>
<p>The most interesting keyword here is <code>lex</code>, which is a function that is defined in Haskell’s standard library as part of the <code>GHC.Read</code> module. The <code>unfoldr</code> function also deserves some explanation, but just as before, it wouldn’t be practical to go into much detail here.</p>
<p>So far, so good. Let’s apply our tokenizing function to the C code:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: <span class="kw">let</span> tokenized_cfs_code <span class="fu">=</span> tokenize_this sample_cfs_code
λ:</code></pre>
<p>Finally, let’s view the resulting stream of tokens:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">λ: mapM_ print tokenized_cfs_code
<span class="st">&quot;static&quot;</span>
<span class="st">&quot;void&quot;</span>
<span class="st">&quot;__enqueue_entity&quot;</span>
<span class="st">&quot;(&quot;</span>
<span class="st">&quot;struct&quot;</span>
<span class="st">&quot;cfs_rq&quot;</span>
<span class="st">&quot;*&quot;</span>
<span class="st">&quot;cfs_rq&quot;</span>
<span class="st">&quot;,&quot;</span>
<span class="st">&quot;struct&quot;</span>
<span class="st">&quot;sched_entity&quot;</span>
<span class="st">&quot;*&quot;</span>
<span class="st">&quot;se&quot;</span>
<span class="st">&quot;)&quot;</span>
<span class="st">&quot;{&quot;</span>
<span class="st">&quot;struct&quot;</span>
<span class="st">&quot;rb_node&quot;</span>
<span class="st">&quot;**&quot;</span>
<span class="st">&quot;link&quot;</span>
<span class="st">&quot;=&quot;</span>
<span class="st">&quot;&amp;&quot;</span>
<span class="st">&quot;cfs_rq&quot;</span>
<span class="st">&quot;-&gt;&quot;</span>
[ <span class="fu">...</span> many more tokens <span class="dt">I&#39;m</span> not showing here <span class="fu">...</span> ]
<span class="st">&quot;rb_insert_color&quot;</span>
<span class="st">&quot;(&quot;</span>
<span class="st">&quot;&amp;&quot;</span>
<span class="st">&quot;se&quot;</span>
<span class="st">&quot;-&gt;&quot;</span>
<span class="st">&quot;run_node&quot;</span>
<span class="st">&quot;,&quot;</span>
<span class="st">&quot;&amp;&quot;</span>
<span class="st">&quot;cfs_rq&quot;</span>
<span class="st">&quot;-&gt;&quot;</span>
<span class="st">&quot;tasks_timeline&quot;</span>
<span class="st">&quot;)&quot;</span>
<span class="st">&quot;;&quot;</span>
<span class="st">&quot;}&quot;</span>
λ:</code></pre>
<p>You can use this approach to help your language design efforts, if you plan on inventing your own DSL, or even your own general-purpose programming language. Once your source code is tokenized, you can now parse the stream of tokens into the target Haskell data structures using a technique called combinator parsing, which is where the Haskell programming language really shines.</p>
</section>
<section id="end-of-part-1" class="level3">
<h3>End of part 1</h3>
<p>That’s it for part 1 – there will be more to come.</p>
<p>If you’re interested in picking up Haskell, there are a number of very good free online resources (<a href="https://www.fpcomplete.com/school">1</a>, <a href="http://learnyouahaskell.com/">2</a>, <a href="http://book.realworldhaskell.org/">3</a>), as well as classes and workshops held in various locations.</p>
<p>Speaking of Haskell classes and workshops, allow me to draw your attention to a project called <a href="http://lambda.rosedu.org/#english">lambda.rosedu.org</a>, which is an instructor-led, in-depth, hands-on workshop on functional programming centered around Haskell, Scala and Clojure. The workshop is free of charge, but the standards for admittance are fairly high (you will need to solve a few programming as well as logic problems). The workshop will be hosted by ROSEdu at the department for Computer Science of the POLITEHNICA University of Bucharest some time during the summer of 2014. The topics I glossed over – due to brevity concerns – in this blog post will be covered in depth during the workshop.</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Tue, 07 Jan 2014 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/haskell-part1.html</guid>
</item>
<item>
    <title>Facebook Hackathon Live Blogging</title>
    <link>http://techblog.rosedu.org/facebook-hackathon-live-blogging.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/facebook-hackathon-live-blogging.html" title="Facebook Hackathon Live Blogging">Facebook Hackathon Live Blogging</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on October 19, 2013</span>
      by
      <span class="author"><a href="/people/alex-palcuie.html">Alex Palcuie</a>, <a href="/people/marius-ungureanu.html">Marius Ungureanu</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/facebook.html">facebook</a>, <a href="/tags/hackathon.html">hackathon</a>, <a href="/tags/live.html">live</a>, <a href="/tags/blogging.html">blogging</a>, <a href="/tags/coders.html">coders</a></span>
      </span>

      <div class="right">
<img style="float:right" width="300" height="300" src="http://distilleryimage10.ak.instagram.com/b88daa3e38a911e3893622000a1fcd0b_7.jpg">
</div>
<section id="pm" class="level4">
<h4>3:30PM</h4>
<p>Ladies and gentlemen, fast hackers and coder perfectionists, web developers and mobile app creators, we present you the first edition of the Facebook hackathon in Romania. Organized by your favorite open-source community ROSEdu, the volunteers have been busy all morning preparing the workspace for the 15 participating teams. We have pizza, beer and a mountain of bean bags for people who <em>move fast and break things</em>.</p>
<!--more-->

<div style="clear:both;"></div>

</section>
<section id="pm-1" class="level4">
<h4>3:30PM</h4>
<p>People have started their IDEs (or text editors for more hardcore people) and started installing their gems (Ruby guy here sorry). After a quick intro from the organizers about the rules, the Facebook engineers presented their skills and their expectations: it’s fun to code, but it’s awesome <strong>to ship</strong>. So happy shipping hackers!</p>
<div class="center">
<img width="600" height="400" src="https://fbcdn-sphotos-g-a.akamaihd.net/hphotos-ak-ash3/1381306_602864479775589_1298026562_n.jpg">
</div>
</section>
<section id="pm-2" class="level4">
<h4>5:30PM</h4>
<p>A brief pause and all the keyboard presses have stopped. The Facebook representatives have given out a random prize! One Facebook T-shirt. Congratulations to Andrei Duma! People are now back to coding and making their ideas come to life: <strong>done is better than perfect</strong>.</p>
<div class="center">
<img width="600" height="400" src="/images/facebook-hackathon/premii_facebook.jpg">
</div>
</section>
<section id="first-team" class="level4">
<h4>First team</h4>
<p>Only 4 hours in the event! We have interviewed some of the participants and they’re coding, designing and implementing their application basis! The first team we interviewed is <a href="https://github.com/rosedu/3_awesome_guyes_and_a_llama">3_awesome_guys_and_a_llama</a>. These students from the University “Politehnica” of Bucharest are writing an Event Planner. From what they told us, it’s an application which tries to help people organize events for them and their friends for their night out. It’s more focused on location, than being focused on time, so they can make it a planned drink-up or dance-off. They integrate it with the Facebook Places API and would like to have bars, clubs and restaurants use their app so people can make reservations. As technology stack, they have Python on top of Google App Engine. One of the devs said that he learned about it on a <a href="https://www.udacity.com/course/cs253">Udacity course</a> which I recommend it to you. They also plan to use Twitter’s Bootstrap library because they do not have enough frontend experience.</p>
<div class="center">
<img width="600" height="400" src="/images/facebook-hackathon/two_guys_llama.JPG">
</div>
</section>
<section id="be-green-recycle" class="level4">
<h4>Be green, recycle</h4>
<p>You are a human, walking down and you see a big pile of garbage. It’s a scenario common here in Romania. But what if you have an app for cleaning it? That’s what <a href="https://github.com/rosedu/sudoRecycle">sudoRecycle</a> is trying to do with their Android idea. You see the junk, take a photo, tag it with the GPS location and send it to their servers. Using their backend written in PHP, they will send teams of robots that will clean the area. Because we human beings are really lazy, they plan to use the Facebook API for gamification, so you could level up in cleaning the world.</p>
<div class="center">
<img width="600" height="400" src="/images/facebook-hackathon/sudo_recycle.JPG">
</div>
</section>
<section id="explore-the-underground" class="level4">
<h4>Explore the underground</h4>
<p>We’ve all endured the lack of knowledge of moving around Bucharest, if we haven’t lived here. But <a href="https://github.com/rosedu/Dark_side_of_the_moon">dark_side_of_the_moon</a> is going to remedy this with their offline mobile subway connection app. You want to get from X to Y using the shortest route. It also wants to tell you what ground-level public transportation is there and what you can visit. Furthermore they want it to tell your friends where you’ve been after you used its functionality to check-in at your destination. Under the hood, it’s using Android 4.0+ API and they want to integrate with the Facebook API to see the places your friends have visited. The coolest feature they want to code will tell you when the next tube will arrive.</p>
<div class="center">
<img width="600" height="400" src="/images/facebook-hackathon/pink_floyd.jpg">
</div>
</section>
<section id="grails" class="level4">
<h4>GRails</h4>
<p>Did you know that in the year 2013, if you apply to MIT, you must send the papers by fax or postal mail? And after you send them, a person will manually go through them and tell you that the papers have arrived? Or if you get into a university you must write 6 papers with about 60% redundant information? That’s what <a href="https://github.com/rosedu/GRails">GRails</a>, the only team made entirely of girls, is trying to solve, fighting bureaucracy with Rails 4. Now with 100% less paper involved!</p>
<div class="center">
<img width="600" height="400" src="/images/facebook-hackathon/grails.jpg">
</div>
</section>
<section id="hiking" class="level4">
<h4>Hiking</h4>
<p>Everybody knows that Romania has some of the best hiking routes, beautiful views and mysterious mountains. And who doesn’t want to know what trips you can make in the wild nature? Well, you can now check out a map and see what is available for adventurers! The map also shows you elevation, so you know if it’s a long road and also an abrupt road. A Django platform by <a href="https://github.com/rosedu/saltaretii">saltaretii</a> should be enough to support this paradise for nature’s explorers!</p>
<div class="center">
<img width="600" height="400" src="/images/facebook-hackathon/saltaretii.jpg">
</div>
</section>
<section id="i-want-to-ride-my-bicycle-i-want-to-ride-my-bike" class="level4">
<h4>I want to ride my bicycle, I want to ride my bike</h4>
<p>2 wheels, foot power and long distance travelling made easy! These two guys are achieving the awesome tool that brings bikers a dream app come true! Using complex algorithms, they want to give bikers many possible routes from one place to another. You can choose your own type of road, either abrupt and short or longer and less steep. The point? You can choose which kind of road you want and which is fit for you! If that is not enough, these 2 guys are doing this client side with ClojureScript… yeah, it’s the new functional kid in town which tries to solve the event driven callback hell. <a href="https://github.com/rosedu/flatride">FlatRide</a> on, people!</p>
<div class="center">
<img width="600" height="400" src="/images/facebook-hackathon/flatride.jpg">
</div>
<div class="right">
<img src="/images/facebook-hackathon/jackson.jpg">
</div>
</section>
<section id="jackson-gabbard" class="level4">
<h4><a href="https://www.facebook.com/jg">Jackson Gabbard</a></h4>
<p>From an English major in Tennessee, to the 300th Facebook employee, to the 4th one to move in the new London office. He works on developer tools for the engineers and oversees some of the most important components like <em>Tasks</em> which devs open daily to get their job done. He is a self-taught hacker and he had an enlightment moment about the power of programming the first time he used the array structure.</p>
<p>He was really communicative and willing to tell us of his opinions, about the event, mentioning that he’s amazed about the main focus of students. ‘Transportation’, ‘Finding things’ and ‘Group organization’ are recurrent themes. He said some of his coworkers are Romanian and he thinks Romania is a land where lots of engineers are being created. Proud to be a full-time hackers around here!</p>
<p>We also asked him about the Bootcamp in London, which is about learning to code. And guess what? Even executives go through these preparations to get into Facebook. The engineering team has lots of fun hacking in that period of education. It teaches you how to love the company, you get to learn the ropes while communicating and interact with other mind-like people.</p>
<p>Finally he has participated in lockdowns each year. These are periods of time when teams gather in a room and stay there for several days (usually 30) and ship a big feature. Pretty hardcore, but that’s life at Facebook.</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Sat, 19 Oct 2013 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/facebook-hackathon-live-blogging.html</guid>
</item>
<item>
    <title>Shell tips and tricks for log files</title>
    <link>http://techblog.rosedu.org/shell-tips-and-tricks-for-file-editing.html</link>
    <description><![CDATA[<div class="unit-inner unit-article-inner">
  <div class="content">
    <div class="bd">
      <header>
        <div class="unit-head">
          <div class="unit-inner unit-head-inner">
            <h1 class="h2 entry-title">
              <a class="post_title" href="/shell-tips-and-tricks-for-file-editing.html" title="Shell tips and tricks for log files">Shell tips and tricks for log files</a>
            </h1>
          </div><!-- unit-inner -->
        </div><!-- unit-head -->
      </header>

      <span class="date">
      <span class="published">Published on June 20, 2013</span>
      by
      <span class="author"><a href="/people/alexandru-juncu.html">Alexandru Juncu</a></span>
      </span>

      <br/>
      <span class="meta">
        Tagged:
        <span class="tags"><a href="/tags/cli.html">CLI</a>, <a href="/tags/bash.html">bash</a>, <a href="/tags/shell.html">shell</a>, <a href="/tags/files.html">files</a>, <a href="/tags/text.html">text</a>, <a href="/tags/truncate.html">truncate</a>, <a href="/tags/tee.html">tee</a>, <a href="/tags/tail.html">tail</a>, <a href="/tags/follow.html">follow</a></span>
      </span>

      <p>Here are are some small things you might find useful when you need to deal with text files. In the Linux/Unix world, a lot of things are text files, so you need to know how to efficiently handle them. If you are a sysadmin, you need to look at <strong>log files</strong> for most of your work time and the following might come in handy.</p>
<!--more-->

<section id="following-a-log-file" class="level3">
<h3>Following a log file</h3>
<p>Take your <code>$GENERIC_SERVICE</code> on your server that generates a lot of logs. You could open a <strong>text editor</strong> like <code>vi</code> or <code>emacs</code> to view the logs or use <code>tail</code> to see the latest lines (or a combination of tail and <code>head</code>). But you sometimes you need to view contents of the log in real time (while the service writes the lines, you read them). This is where the best use for the tail command comes in: the <code>--follow</code> flag.</p>
<pre><code>tail -f /var/log/mylog</code></pre>
<p>Tail usually creates a process that prints a few lines (the lines that exist when you run it), but with the <code>-f</code> flag, the tail process keeps running and prints new lines as the file is being appended. The process will close when the uses issues the <code>Cltr-D</code> (end of file) command.</p>
</section>
<section id="truncating-a-file" class="level3">
<h3>Truncating a file</h3>
<p>Maybe you need to clear the contents of a log file that has gotten too big. You could do a <code>rm</code> on the file and let the service write the new logs in a new file. Some services are picky and need the file to already exist, so you could use the <code>touch</code> command (that “updates” an existing file) which has the interesting side effect when applied on a non existing file: to create an empty file (a new inode with no data blocks).</p>
<p>But you just want to empty a file (same inode, just the contents cleared). You could use the <code>truncate</code> command with the size flag of 0 bytes (<code>-s 0</code>). Or make use of the redirect operator <code>&gt;</code>.</p>
<pre><code>:&gt;file</code></pre>
<p>or just</p>
<pre><code>&gt;file</code></pre>
<p>These will open the file, and redirect nothing into it. Since it is not appending anything, the contents will be erased. <code>:</code> is the no-op command so nothing will actually be done, but the shell with open and write (well … nothing) into the file because of the redirection operator <code>&gt;</code>.</p>
</section>
<section id="one-input-two-outputs" class="level3">
<h3>One input, two outputs</h3>
<p>Some programs do not have a logging system programmed into them and just print messages to standard output. Maybe you want to save that output into a file for future use. This is simple to do with a file redirection:</p>
<pre><code>./myprogram &gt; my_log_file</code></pre>
<p>But if you do this, you will lose the output to the (virtual) terminal. A very interesting command is <code>tee</code>, that takes an input and writes to standard output, but also writes into a specified file. You need to pipe the output of a process into tee like this:</p>
<pre><code>./myprogram | tee my_log_file</code></pre>
<p>Now you have both real time printing of the messages and you have them saved for future use.</p>
<p>Hope this helps!</p>
</section>

    </div>
  </div>
</div>
]]></description>
    <pubDate>Thu, 20 Jun 2013 00:00:00 UT</pubDate>
    <guid>http://techblog.rosedu.org/shell-tips-and-tricks-for-file-editing.html</guid>
</item>

    </channel> 
</rss>
